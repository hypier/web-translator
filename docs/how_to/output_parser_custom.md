---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/how_to/output_parser_custom.ipynb
---

# å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰è¾“å‡ºè§£æå™¨

åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½å¸Œæœ›å®ç°ä¸€ä¸ªè‡ªå®šä¹‰è§£æå™¨ï¼Œå°†æ¨¡å‹è¾“å‡ºç»“æ„åŒ–ä¸ºè‡ªå®šä¹‰æ ¼å¼ã€‚

å®ç°è‡ªå®šä¹‰è§£æå™¨æœ‰ä¸¤ç§æ–¹æ³•ï¼š

1. ä½¿ç”¨ LCEL ä¸­çš„ `RunnableLambda` æˆ– `RunnableGenerator` -- æˆ‘ä»¬å¼ºçƒˆæ¨èè¿™ç§æ–¹æ³•ç”¨äºå¤§å¤šæ•°ç”¨ä¾‹
2. é€šè¿‡ä»åŸºç¡€ç±»ä¹‹ä¸€ç»§æ‰¿æ¥è¿›è¡Œè¾“å‡ºè§£æ -- è¿™æ˜¯æ¯”è¾ƒå›°éš¾çš„å®ç°æ–¹å¼

è¿™ä¸¤ç§æ–¹æ³•ä¹‹é—´çš„åŒºåˆ«ä¸»è¦æ˜¯è¡¨é¢çš„ï¼Œä¸»è¦ä½“ç°åœ¨è§¦å‘çš„å›è°ƒï¼ˆä¾‹å¦‚ï¼Œ`on_chain_start` ä¸ `on_parser_start`ï¼‰ä»¥åŠåœ¨åƒ LangSmith è¿™æ ·çš„è¿½è¸ªå¹³å°ä¸­å¯è§†åŒ– `RunnableLambda` ä¸è§£æå™¨çš„æ–¹å¼ã€‚

## å¯è¿è¡Œçš„ Lambda å’Œç”Ÿæˆå™¨

æ¨èçš„è§£ææ–¹å¼æ˜¯ä½¿ç”¨ **å¯è¿è¡Œçš„ Lambda** å’Œ **å¯è¿è¡Œçš„ç”Ÿæˆå™¨**ï¼

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†è¿›è¡Œä¸€ä¸ªç®€å•çš„è§£æï¼Œå®ƒä¼šåè½¬æ¨¡å‹è¾“å‡ºçš„å¤§å°å†™ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœæ¨¡å‹è¾“å‡ºï¼šâ€œMeowâ€ï¼Œè§£æå™¨å°†ç”Ÿæˆâ€œmEOWâ€ã€‚

```python
from typing import Iterable

from langchain_anthropic.chat_models import ChatAnthropic
from langchain_core.messages import AIMessage, AIMessageChunk

model = ChatAnthropic(model_name="claude-2.1")


def parse(ai_message: AIMessage) -> str:
    """Parse the AI message."""
    return ai_message.content.swapcase()


chain = model | parse
chain.invoke("hello")
```

```output
'hELLO!'
```

:::tip

LCEL åœ¨ä½¿ç”¨ `|` è¯­æ³•ç»„åˆæ—¶ï¼Œä¼šè‡ªåŠ¨å°†å‡½æ•° `parse` å‡çº§ä¸º `RunnableLambda(parse)`ã€‚

å¦‚æœä½ ä¸å–œæ¬¢è¿™æ ·ï¼Œä½ å¯ä»¥æ‰‹åŠ¨å¯¼å…¥ `RunnableLambda`ï¼Œç„¶åè¿è¡Œ `parse = RunnableLambda(parse)`ã€‚
:::

æµå¼ä¼ è¾“æœ‰æ•ˆå—ï¼Ÿ

```python
for chunk in chain.stream("tell me about yourself in one sentence"):
    print(chunk, end="|", flush=True)
```
```output
i'M cLAUDE, AN ai ASSISTANT CREATED BY aNTHROPIC TO BE HELPFUL, HARMLESS, AND HONEST.|
```
ä¸ï¼Œå®ƒæ— æ•ˆï¼Œå› ä¸ºè§£æå™¨åœ¨è§£æè¾“å‡ºä¹‹å‰ä¼šèšåˆè¾“å…¥ã€‚

å¦‚æœæˆ‘ä»¬æƒ³å®ç°ä¸€ä¸ªæµå¼è§£æå™¨ï¼Œå¯ä»¥è®©è§£æå™¨æ¥å—è¾“å…¥çš„å¯è¿­ä»£å¯¹è±¡ï¼Œå¹¶åœ¨ç»“æœå¯ç”¨æ—¶ç”Ÿæˆç»“æœã€‚

```python
from langchain_core.runnables import RunnableGenerator


def streaming_parse(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:
    for chunk in chunks:
        yield chunk.content.swapcase()


streaming_parse = RunnableGenerator(streaming_parse)
```

:::important

è¯·å°†æµå¼è§£æå™¨åŒ…è£…åœ¨ `RunnableGenerator` ä¸­ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½ä¼šåœæ­¢ä½¿ç”¨ `|` è¯­æ³•è‡ªåŠ¨å‡çº§å®ƒã€‚
:::

```python
chain = model | streaming_parse
chain.invoke("hello")
```

```output
'hELLO!'
```

è®©æˆ‘ä»¬ç¡®è®¤æµå¼ä¼ è¾“æœ‰æ•ˆï¼

```python
for chunk in chain.stream("tell me about yourself in one sentence"):
    print(chunk, end="|", flush=True)
```
```output
i|'M| cLAUDE|,| AN| ai| ASSISTANT| CREATED| BY| aN|THROP|IC| TO| BE| HELPFUL|,| HARMLESS|,| AND| HONEST|.|
```

## ä»è§£æåŸºç±»ç»§æ‰¿

å®ç°è§£æå™¨çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä» `BaseOutputParser`ã€`BaseGenerationOutputParser` æˆ–å…¶ä»–åŸºè§£æå™¨ç»§æ‰¿ï¼Œå…·ä½“å–å†³äºæ‚¨çš„éœ€æ±‚ã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬ **ä¸** æ¨èè¿™ç§æ–¹æ³•ç”¨äºå¤§å¤šæ•°ç”¨ä¾‹ï¼Œå› ä¸ºè¿™ä¼šå¯¼è‡´éœ€è¦ç¼–å†™æ›´å¤šä»£ç è€Œæ²¡æœ‰æ˜¾è‘—çš„å¥½å¤„ã€‚

æœ€ç®€å•çš„è¾“å‡ºè§£æå™¨ç±»å‹æ‰©å±•äº† `BaseOutputParser` ç±»ï¼Œå¹¶å¿…é¡»å®ç°ä»¥ä¸‹æ–¹æ³•ï¼š

* `parse`ï¼šæ¥å—æ¨¡å‹çš„å­—ç¬¦ä¸²è¾“å‡ºå¹¶è¿›è¡Œè§£æ
* ï¼ˆå¯é€‰ï¼‰`_type`ï¼šè¯†åˆ«è§£æå™¨çš„åç§°ã€‚

å½“èŠå¤©æ¨¡å‹æˆ– LLM çš„è¾“å‡ºæ ¼å¼ä¸æ­£ç¡®æ—¶ï¼Œå¯ä»¥æŠ›å‡º `OutputParserException` æ¥è¡¨ç¤ºè§£æå› è¾“å…¥é”™è¯¯è€Œå¤±è´¥ã€‚ä½¿ç”¨æ­¤å¼‚å¸¸å¯ä»¥è®©ä½¿ç”¨è§£æå™¨çš„ä»£ç ä»¥ä¸€è‡´çš„æ–¹å¼å¤„ç†å¼‚å¸¸ã€‚

:::tip è§£æå™¨æ˜¯å¯è¿è¡Œçš„ï¼ ğŸƒ

å› ä¸º `BaseOutputParser` å®ç°äº† `Runnable` æ¥å£ï¼Œæ‰€ä»¥æ‚¨ä»¥è¿™ç§æ–¹å¼åˆ›å»ºçš„ä»»ä½•è‡ªå®šä¹‰è§£æå™¨éƒ½å°†æˆä¸ºæœ‰æ•ˆçš„ LangChain å¯è¿è¡Œå¯¹è±¡ï¼Œå¹¶å°†å—ç›Šäºè‡ªåŠ¨å¼‚æ­¥æ”¯æŒã€æ‰¹é‡æ¥å£ã€æ—¥å¿—æ”¯æŒç­‰ã€‚
:::

### ç®€å•è§£æå™¨

è¿™æ˜¯ä¸€ä¸ªç®€å•çš„è§£æå™¨ï¼Œå¯ä»¥è§£æ**å­—ç¬¦ä¸²**è¡¨ç¤ºçš„å¸ƒå°”å€¼ï¼ˆä¾‹å¦‚ï¼Œ`YES`æˆ–`NO`ï¼‰ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºç›¸åº”çš„`boolean`ç±»å‹ã€‚

```python
from langchain_core.exceptions import OutputParserException
from langchain_core.output_parsers import BaseOutputParser


# [bool]æè¿°äº†ä¸€ä¸ªé€šç”¨çš„å‚æ•°åŒ–ã€‚
# å®ƒåŸºæœ¬ä¸ŠæŒ‡ç¤ºè§£æçš„è¿”å›ç±»å‹
# åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿”å›ç±»å‹æ˜¯Trueæˆ–False
class BooleanOutputParser(BaseOutputParser[bool]):
    """è‡ªå®šä¹‰å¸ƒå°”è§£æå™¨ã€‚"""

    true_val: str = "YES"
    false_val: str = "NO"

    def parse(self, text: str) -> bool:
        cleaned_text = text.strip().upper()
        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):
            raise OutputParserException(
                f"BooleanOutputParser expected output value to either be "
                f"{self.true_val} or {self.false_val} (case-insensitive). "
                f"Received {cleaned_text}."
            )
        return cleaned_text == self.true_val.upper()

    @property
    def _type(self) -> str:
        return "boolean_output_parser"
```

```python
parser = BooleanOutputParser()
parser.invoke("YES")
```

```output
True
```

```python
try:
    parser.invoke("MEOW")
except Exception as e:
    print(f"Triggered an exception of type: {type(e)}")
```
```output
Triggered an exception of type: <class 'langchain_core.exceptions.OutputParserException'>
```
è®©æˆ‘ä»¬æµ‹è¯•æ›´æ”¹å‚æ•°åŒ–

```python
parser = BooleanOutputParser(true_val="OKAY")
parser.invoke("OKAY")
```

```output
True
```

è®©æˆ‘ä»¬ç¡®è®¤å…¶ä»–LCELæ–¹æ³•æ˜¯å¦å­˜åœ¨

```python
parser.batch(["OKAY", "NO"])
```

```output
[True, False]
```

```python
await parser.abatch(["OKAY", "NO"])
```

```output
[True, False]
```

```python
from langchain_anthropic.chat_models import ChatAnthropic

anthropic = ChatAnthropic(model_name="claude-2.1")
anthropic.invoke("say OKAY or NO")
```

```output
AIMessage(content='OKAY')
```

è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹æˆ‘ä»¬çš„è§£æå™¨æ˜¯å¦æœ‰æ•ˆï¼

```python
chain = anthropic | parser
chain.invoke("say OKAY or NO")
```

```output
True
```

:::note
è¯¥è§£æå™¨å¯ä»¥å¤„ç†æ¥è‡ªLLMçš„è¾“å‡ºï¼ˆå­—ç¬¦ä¸²ï¼‰æˆ–æ¥è‡ªèŠå¤©æ¨¡å‹çš„è¾“å‡ºï¼ˆ`AIMessage`ï¼‰!
:::

### è§£æåŸå§‹æ¨¡å‹è¾“å‡º

æœ‰æ—¶ï¼Œæ¨¡å‹è¾“å‡ºä¸­é™¤äº†åŸå§‹æ–‡æœ¬ä¹‹å¤–è¿˜æœ‰é¢å¤–çš„é‡è¦å…ƒæ•°æ®ã€‚ä¸€ä¸ªä¾‹å­æ˜¯å·¥å…·è°ƒç”¨ï¼Œå…¶ä¸­æ‰“ç®—ä¼ é€’ç»™è¢«è°ƒç”¨å‡½æ•°çš„å‚æ•°ä»¥å•ç‹¬çš„å±æ€§è¿”å›ã€‚å¦‚æœæ‚¨éœ€è¦è¿™ç§æ›´ç»†ç²’åº¦çš„æ§åˆ¶ï¼Œæ‚¨å¯ä»¥æ”¹ä¸ºå­ç±»åŒ– `BaseGenerationOutputParser` ç±»ã€‚

æ­¤ç±»éœ€è¦ä¸€ä¸ªå•ä¸€çš„æ–¹æ³• `parse_result`ã€‚è¯¥æ–¹æ³•æ¥å—åŸå§‹æ¨¡å‹è¾“å‡ºï¼ˆä¾‹å¦‚ï¼Œ`Generation` æˆ– `ChatGeneration` çš„åˆ—è¡¨ï¼‰å¹¶è¿”å›è§£æåçš„è¾“å‡ºã€‚

æ”¯æŒ `Generation` å’Œ `ChatGeneration` ä½¿è§£æå™¨èƒ½å¤Ÿä¸å¸¸è§„ LLM ä»¥åŠèŠå¤©æ¨¡å‹ä¸€èµ·å·¥ä½œã€‚

```python
from typing import List

from langchain_core.exceptions import OutputParserException
from langchain_core.messages import AIMessage
from langchain_core.output_parsers import BaseGenerationOutputParser
from langchain_core.outputs import ChatGeneration, Generation


class StrInvertCase(BaseGenerationOutputParser[str]):
    """ä¸€ä¸ªç¤ºä¾‹è§£æå™¨ï¼Œå®ƒåè½¬æ¶ˆæ¯ä¸­å­—ç¬¦çš„å¤§å°å†™ã€‚

    è¿™æ˜¯ä¸€ä¸ªä»…ç”¨äºæ¼”ç¤ºç›®çš„çš„ç¤ºä¾‹è§£æï¼Œæ—¨åœ¨ä½¿ç¤ºä¾‹å°½å¯èƒ½ç®€å•ã€‚
    """

    def parse_result(self, result: List[Generation], *, partial: bool = False) -> str:
        """å°†æ¨¡å‹ç”Ÿæˆçš„åˆ—è¡¨è§£æä¸ºç‰¹å®šæ ¼å¼ã€‚

        å‚æ•°ï¼š
            result: è¦è§£æçš„ç”Ÿæˆåˆ—è¡¨ã€‚å‡è®¾è¿™äº›ç”Ÿæˆæ˜¯å•ä¸ªæ¨¡å‹è¾“å…¥çš„ä¸åŒå€™é€‰è¾“å‡ºã€‚
                è®¸å¤šè§£æå™¨å‡è®¾åªä¼ å…¥äº†ä¸€ä¸ªç”Ÿæˆã€‚
                æˆ‘ä»¬å°†å¯¹æ­¤è¿›è¡Œæ–­è¨€ã€‚
            partial: æ˜¯å¦å…è®¸éƒ¨åˆ†ç»“æœã€‚è¿™ç”¨äºæ”¯æŒæµå¼å¤„ç†çš„è§£æå™¨ã€‚
        """
        if len(result) != 1:
            raise NotImplementedError(
                "æ­¤è¾“å‡ºè§£æå™¨åªèƒ½ä¸å•ä¸ªç”Ÿæˆä¸€èµ·ä½¿ç”¨ã€‚"
            )
        generation = result[0]
        if not isinstance(generation, ChatGeneration):
            # è¯´æ˜è¿™ä¸ªä»…é€‚ç”¨äºèŠå¤©ç”Ÿæˆ
            raise OutputParserException(
                "æ­¤è¾“å‡ºè§£æå™¨åªèƒ½ä¸èŠå¤©ç”Ÿæˆä¸€èµ·ä½¿ç”¨ã€‚"
            )
        return generation.message.content.swapcase()


chain = anthropic | StrInvertCase()
```

è®©æˆ‘ä»¬æ¥çœ‹çœ‹æ–°çš„è§£æå™¨ï¼å®ƒåº”è¯¥åè½¬æ¨¡å‹çš„è¾“å‡ºã€‚

```python
chain.invoke("Tell me a short sentence about yourself")
```

```output
'hELLO! mY NAME IS cLAUDE.'
```