---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/integrations/chat/premai.ipynb
sidebar_label: PremAI
---

# ChatPremAI

[PremAI](https://premai.io/) æ˜¯ä¸€ä¸ªä¸€ä½“åŒ–å¹³å°ï¼Œç®€åŒ–äº†ç”±ç”Ÿæˆæ€§äººå·¥æ™ºèƒ½é©±åŠ¨çš„å¼ºå¤§ã€ç”Ÿäº§å°±ç»ªåº”ç”¨ç¨‹åºçš„åˆ›å»ºã€‚é€šè¿‡ç®€åŒ–å¼€å‘è¿‡ç¨‹ï¼ŒPremAI ä½¿æ‚¨èƒ½å¤Ÿä¸“æ³¨äºå¢å¼ºç”¨æˆ·ä½“éªŒå¹¶æ¨åŠ¨åº”ç”¨ç¨‹åºçš„æ•´ä½“å¢é•¿ã€‚æ‚¨å¯ä»¥å¿«é€Ÿå¼€å§‹ä½¿ç”¨æˆ‘ä»¬çš„å¹³å° [è¿™é‡Œ](https://docs.premai.io/quick-start)ã€‚

æ­¤ç¤ºä¾‹ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ LangChain ä¸ä¸åŒèŠå¤©æ¨¡å‹äº¤äº’ï¼Œä½¿ç”¨ `ChatPremAI`

### å®‰è£…ä¸è®¾ç½®

æˆ‘ä»¬é¦–å…ˆå®‰è£… `langchain` å’Œ `premai-sdk`ã€‚æ‚¨å¯ä»¥è¾“å…¥ä»¥ä¸‹å‘½ä»¤è¿›è¡Œå®‰è£…ï¼š

```bash
pip install premai langchain
```

åœ¨ç»§ç»­ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²åœ¨ PremAI ä¸Šæ³¨å†Œäº†è´¦æˆ·å¹¶åˆ›å»ºäº†é¡¹ç›®ã€‚å¦‚æœæ²¡æœ‰ï¼Œè¯·å‚è€ƒ [å¿«é€Ÿå…¥é—¨](https://docs.premai.io/introduction) æŒ‡å—ä»¥å¼€å§‹ä½¿ç”¨ PremAI å¹³å°ã€‚åˆ›å»ºæ‚¨çš„ç¬¬ä¸€ä¸ªé¡¹ç›®å¹¶è·å–æ‚¨çš„ API å¯†é’¥ã€‚

```python
from langchain_community.chat_models import ChatPremAI
from langchain_core.messages import HumanMessage, SystemMessage
```

### åœ¨LangChainä¸­è®¾ç½®PremAIå®¢æˆ·ç«¯

ä¸€æ—¦æˆ‘ä»¬å¯¼å…¥äº†æ‰€éœ€çš„æ¨¡å—ï¼Œè®©æˆ‘ä»¬è®¾ç½®æˆ‘ä»¬çš„å®¢æˆ·ç«¯ã€‚ç°åœ¨å‡è®¾æˆ‘ä»¬çš„ `project_id` æ˜¯ `8`ã€‚ä½†è¯·ç¡®ä¿ä½¿ç”¨æ‚¨çš„é¡¹ç›®IDï¼Œå¦åˆ™ä¼šæŠ›å‡ºé”™è¯¯ã€‚

è¦å°†langchainä¸premä¸€èµ·ä½¿ç”¨ï¼Œæ‚¨ä¸éœ€è¦ä¼ é€’ä»»ä½•æ¨¡å‹åç§°æˆ–è®¾ç½®ä»»ä½•ä¸æˆ‘ä»¬çš„èŠå¤©å®¢æˆ·ç«¯ç›¸å…³çš„å‚æ•°ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒå°†ä½¿ç”¨åœ¨[LaunchPad](https://docs.premai.io/get-started/launchpad)ä¸­ä½¿ç”¨çš„æ¨¡å‹åç§°å’Œå‚æ•°ã€‚

> æ³¨æ„ï¼šå¦‚æœæ‚¨åœ¨è®¾ç½®å®¢æˆ·ç«¯æ—¶æ›´æ”¹äº† `model` æˆ–ä»»ä½•å…¶ä»–å‚æ•°ï¼Œå¦‚ `temperature` æˆ– `max_tokens`ï¼Œå®ƒå°†è¦†ç›–åœ¨LaunchPadä¸­ä½¿ç”¨çš„ç°æœ‰é»˜è®¤é…ç½®ã€‚

```python
import getpass
import os

# ç¬¬ä¸€æ­¥æ˜¯è®¾ç½®ç¯å¢ƒå˜é‡ã€‚
# æ‚¨ä¹Ÿå¯ä»¥åœ¨å®ä¾‹åŒ–æ¨¡å‹æ—¶ä¼ é€’APIå¯†é’¥ï¼Œä½†è¿™
# å±äºæœ€ä½³å®è·µï¼Œå»ºè®®å°†å…¶è®¾ç½®ä¸ºç¯å¢ƒå˜é‡ã€‚

if os.environ.get("PREMAI_API_KEY") is None:
    os.environ["PREMAI_API_KEY"] = getpass.getpass("PremAI API Key:")
```

```python
# é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒå°†ä½¿ç”¨é€šè¿‡å¹³å°éƒ¨ç½²çš„æ¨¡å‹
# åœ¨æˆ‘çš„ä¾‹å­ä¸­ï¼Œå®ƒæ˜¯ "gpt-4o"

chat = ChatPremAI(project_id=1234, model_name="gpt-4o")
```

### èŠå¤©è¡¥å…¨

`ChatPremAI` æ”¯æŒä¸¤ç§æ–¹æ³•ï¼š`invoke`ï¼ˆä¸ `generate` ç›¸åŒï¼‰å’Œ `stream`ã€‚

ç¬¬ä¸€ç§æ–¹æ³•å°†ç»™æˆ‘ä»¬ä¸€ä¸ªé™æ€ç»“æœï¼Œè€Œç¬¬äºŒç§æ–¹æ³•å°†é€ä¸ªæµå¼ä¼ è¾“ä»¤ç‰Œã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•ç”Ÿæˆç±»ä¼¼èŠå¤©çš„è¡¥å…¨ã€‚

```python
human_message = HumanMessage(content="Who are you?")

response = chat.invoke([human_message])
print(response.content)
```
```output
I am an AI language model created by OpenAI, designed to assist with answering questions and providing information based on the context provided. How can I help you today?
```
ä»¥ä¸Šçœ‹èµ·æ¥å¾ˆæœ‰è¶£ï¼Œå¯¹å§ï¼Ÿæˆ‘å°†æˆ‘çš„é»˜è®¤å¯åŠ¨æ¿ç³»ç»Ÿæç¤ºè®¾ç½®ä¸ºï¼š`Always sound like a pirate` å¦‚æœéœ€è¦ï¼Œæ‚¨ä¹Ÿå¯ä»¥è¦†ç›–é»˜è®¤ç³»ç»Ÿæç¤ºã€‚ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥è¿™æ ·åšçš„æ–¹æ³•ã€‚

```python
system_message = SystemMessage(content="You are a friendly assistant.")
human_message = HumanMessage(content="Who are you?")

chat.invoke([system_message, human_message])
```

```output
AIMessage(content="I'm your friendly assistant! How can I help you today?", response_metadata={'document_chunks': [{'repository_id': 1985, 'document_id': 1306, 'chunk_id': 173899, 'document_name': '[D] Difference between sparse and dense informatiâ€¦', 'similarity_score': 0.3209080100059509, 'content': "with the difference or anywhere\nwhere I can read about it?\n\n\n      17                  9\n\n\n      u/ScotiabankCanada        â€¢  Promoted\n\n\n                       Accelerate your study permit process\n                       with Scotiabank's Student GIC\n                       Program. We're here to help you turâ€¦\n\n\n                       startright.scotiabank.com         Learn More\n\n\n                            Add a Comment\n\n\nSort by:   Best\n\n\n      DinosParkour      â€¢ 1y ago\n\n\n     Dense Retrieval (DR) m"}]}, id='run-510bbd0e-3f8f-4095-9b1f-c2d29fd89719-0')
```

æ‚¨å¯ä»¥åœ¨è¿™é‡Œæä¾›ç³»ç»Ÿæç¤ºï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```python
chat.invoke([system_message, human_message], temperature=0.7, max_tokens=10, top_p=0.95)
```
```output
/home/anindya/prem/langchain/libs/community/langchain_community/chat_models/premai.py:355: UserWarning: WARNING: Parameter top_p is not supported in kwargs.
  warnings.warn(f"WARNING: Parameter {key} is not supported in kwargs.")
```

```output
AIMessage(content="Hello! I'm your friendly assistant. How can I", response_metadata={'document_chunks': [{'repository_id': 1985, 'document_id': 1306, 'chunk_id': 173899, 'document_name': '[D] Difference between sparse and dense informatiâ€¦', 'similarity_score': 0.3209080100059509, 'content': "with the difference or anywhere\nwhere I can read about it?\n\n\n      17                  9\n\n\n      u/ScotiabankCanada        â€¢  Promoted\n\n\n                       Accelerate your study permit process\n                       with Scotiabank's Student GIC\n                       Program. We're here to help you turâ€¦\n\n\n                       startright.scotiabank.com         Learn More\n\n\n                            Add a Comment\n\n\nSort by:   Best\n\n\n      DinosParkour      â€¢ 1y ago\n\n\n     Dense Retrieval (DR) m"}]}, id='run-c4b06b98-4161-4cca-8495-fd2fc98fa8f8-0')
```

> å¦‚æœæ‚¨åœ¨è¿™é‡Œæ”¾ç½®ç³»ç»Ÿæç¤ºï¼Œå®ƒå°†è¦†ç›–æ‚¨åœ¨ä»å¹³å°éƒ¨ç½²åº”ç”¨ç¨‹åºæ—¶å›ºå®šçš„ç³»ç»Ÿæç¤ºã€‚

### åŸç”Ÿ RAG æ”¯æŒä¸ Prem ä»“åº“

Prem ä»“åº“å…è®¸ç”¨æˆ·ä¸Šä¼ æ–‡æ¡£ï¼ˆ.txtã€.pdf ç­‰ï¼‰å¹¶å°†è¿™äº›ä»“åº“è¿æ¥åˆ° LLMsã€‚æ‚¨å¯ä»¥å°† Prem ä»“åº“è§†ä¸ºåŸç”Ÿ RAGï¼Œå…¶ä¸­æ¯ä¸ªä»“åº“å¯ä»¥è¢«è§†ä¸ºä¸€ä¸ªå‘é‡æ•°æ®åº“ã€‚æ‚¨å¯ä»¥è¿æ¥å¤šä¸ªä»“åº“ã€‚æ‚¨å¯ä»¥åœ¨ [è¿™é‡Œ](https://docs.premai.io/get-started/repositories) äº†è§£æ›´å¤šå…³äºä»“åº“çš„ä¿¡æ¯ã€‚

åœ¨ langchain premai ä¸­ä¹Ÿæ”¯æŒä»“åº“ã€‚ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚

```python
query = "Which models are used for dense retrieval"
repository_ids = [
    1985,
]
repositories = dict(ids=repository_ids, similarity_threshold=0.3, limit=3)
```

é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡ä¸€äº›ä»“åº“ ID æ¥å®šä¹‰æˆ‘ä»¬çš„ä»“åº“ã€‚ç¡®ä¿è¿™äº› ID æ˜¯æœ‰æ•ˆçš„ä»“åº“ IDã€‚æ‚¨å¯ä»¥åœ¨ [è¿™é‡Œ](https://docs.premai.io/get-started/repositories) äº†è§£æ›´å¤šå…³äºå¦‚ä½•è·å–ä»“åº“ ID çš„ä¿¡æ¯ã€‚

> è¯·æ³¨æ„ï¼šä¸ `model_name` ç±»ä¼¼ï¼Œå½“æ‚¨è°ƒç”¨å‚æ•° `repositories` æ—¶ï¼Œæ‚¨å¯èƒ½ä¼šè¦†ç›–åœ¨å¯åŠ¨å¹³å°ä¸­è¿æ¥çš„ä»“åº“ã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä»“åº“ä¸æˆ‘ä»¬çš„èŠå¤©å¯¹è±¡è¿æ¥ï¼Œä»¥è°ƒç”¨åŸºäº RAG çš„ç”Ÿæˆã€‚

```python
import json

response = chat.invoke(query, max_tokens=100, repositories=repositories)

print(response.content)
print(json.dumps(response.response_metadata, indent=4))
```
```output
Dense retrieval models typically include:

1. **BERT-based Models**: Such as DPR (Dense Passage Retrieval) which uses BERT for encoding queries and passages.
2. **ColBERT**: A model that combines BERT with late interaction mechanisms.
3. **ANCE (Approximate Nearest Neighbor Negative Contrastive Estimation)**: Uses BERT and focuses on efficient retrieval.
4. **TCT-ColBERT**: A variant of ColBERT that uses a two-tower
{
    "document_chunks": [
        {
            "repository_id": 1985,
            "document_id": 1306,
            "chunk_id": 173899,
            "document_name": "[D] Difference between sparse and dense informati\u2026",
            "similarity_score": 0.3209080100059509,
            "content": "with the difference or anywhere\nwhere I can read about it?\n\n\n      17                  9\n\n\n      u/ScotiabankCanada        \u2022  Promoted\n\n\n                       Accelerate your study permit process\n                       with Scotiabank's Student GIC\n                       Program. We're here to help you tur\u2026\n\n\n                       startright.scotiabank.com         Learn More\n\n\n                            Add a Comment\n\n\nSort by:   Best\n\n\n      DinosParkour      \u2022 1y ago\n\n\n     Dense Retrieval (DR) m"
        }
    ]
}
```
> ç†æƒ³æƒ…å†µä¸‹ï¼Œæ‚¨æ— éœ€åœ¨æ­¤å¤„è¿æ¥ä»“åº“ ID ä»¥è·å–å¢å¼ºæ£€ç´¢ç”Ÿæˆã€‚å¦‚æœæ‚¨åœ¨ prem å¹³å°ä¸­è¿æ¥äº†ä»“åº“ï¼Œæ‚¨ä»ç„¶å¯ä»¥è·å¾—ç›¸åŒçš„ç»“æœã€‚

### Prem æ¨¡æ¿

å†™ä½œæç¤ºæ¨¡æ¿å¯èƒ½ä¼šéå¸¸æ··ä¹±ã€‚æç¤ºæ¨¡æ¿é€šå¸¸å¾ˆé•¿ï¼Œéš¾ä»¥ç®¡ç†ï¼Œå¹¶ä¸”å¿…é¡»ä¸æ–­è°ƒæ•´ä»¥æ”¹è¿›å¹¶åœ¨æ•´ä¸ªåº”ç”¨ç¨‹åºä¸­ä¿æŒä¸€è‡´ã€‚

ä½¿ç”¨ **Prem**ï¼Œç¼–å†™å’Œç®¡ç†æç¤ºå˜å¾—éå¸¸ç®€å•ã€‚**_Templates_** é€‰é¡¹å¡åœ¨ [launchpad](https://docs.premai.io/get-started/launchpad) å†…éƒ¨å¸®åŠ©æ‚¨ç¼–å†™æ‰€éœ€çš„å¤šä¸ªæç¤ºï¼Œå¹¶åœ¨ SDK ä¸­ä½¿ç”¨è¿™äº›æç¤ºä½¿æ‚¨çš„åº”ç”¨ç¨‹åºè¿è¡Œã€‚æ‚¨å¯ä»¥åœ¨ [è¿™é‡Œ](https://docs.premai.io/get-started/prem-templates) é˜…è¯»æ›´å¤šå…³äºæç¤ºæ¨¡æ¿çš„ä¿¡æ¯ã€‚

è¦åœ¨ LangChain ä¸­åŸç”Ÿä½¿ç”¨ Prem æ¨¡æ¿ï¼Œæ‚¨éœ€è¦å°†ä¸€ä¸ª id ä¼ é€’ç»™ `HumanMessage`ã€‚è¿™ä¸ª id åº”è¯¥æ˜¯æ‚¨æç¤ºæ¨¡æ¿å˜é‡çš„åç§°ã€‚`HumanMessage` ä¸­çš„ `content` åº”è¯¥æ˜¯è¯¥å˜é‡çš„å€¼ã€‚

å‡è®¾ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨çš„æç¤ºæ¨¡æ¿æ˜¯è¿™æ ·çš„ï¼š

```text
Say hello to my name and say a feel-good quote
from my age. My name is: {name} and age is {age}
```

é‚£ä¹ˆæ‚¨çš„ human_messages åº”è¯¥å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
human_messages = [
    HumanMessage(content="Shawn", id="name"),
    HumanMessage(content="22", id="age"),
]
```

å°†è¿™ä¸ª `human_messages` ä¼ é€’ç»™ ChatPremAI å®¢æˆ·ç«¯ã€‚è¯·æ³¨æ„ï¼šä¸è¦å¿˜è®°ä¼ é€’é¢å¤–çš„ `template_id` ä»¥è°ƒç”¨ Prem æ¨¡æ¿ç”Ÿæˆã€‚å¦‚æœæ‚¨ä¸äº†è§£ `template_id`ï¼Œå¯ä»¥åœ¨æˆ‘ä»¬çš„æ–‡æ¡£ä¸­äº†è§£æ›´å¤šä¿¡æ¯ [åœ¨è¿™é‡Œ](https://docs.premai.io/get-started/prem-templates)ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š

```python
template_id = "78069ce8-xxxxx-xxxxx-xxxx-xxx"
response = chat.invoke([human_messages], template_id=template_id)
print(response.content)
```

Prem æ¨¡æ¿åŠŸèƒ½åœ¨æµå¼ä¼ è¾“ä¸­ä¹Ÿå¯ç”¨ã€‚

### æµå¼å¤„ç†

åœ¨æœ¬èŠ‚ä¸­ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨ langchain å’Œ PremAI æµå¼ä¼ è¾“ä»¤ç‰Œã€‚ä»¥ä¸‹æ˜¯æ“ä½œæ–¹æ³•ã€‚

```python
import sys

for chunk in chat.stream("hello how are you"):
    sys.stdout.write(chunk.content)
    sys.stdout.flush()
```
```output
It looks like your message got cut off. If you need information about Dense Retrieval (DR) or any other topic, please provide more details or clarify your question.
```
ç±»ä¼¼äºä¸Šé¢çš„æƒ…å†µï¼Œå¦‚æœæ‚¨æƒ³è¦†ç›–ç³»ç»Ÿæç¤ºå’Œç”Ÿæˆå‚æ•°ï¼Œæ‚¨éœ€è¦æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š

```python
import sys

# For some experimental reasons if you want to override the system prompt then you
# can pass that here too. However it is not recommended to override system prompt
# of an already deployed model.

for chunk in chat.stream(
    "hello how are you",
    system_prompt="act like a dog",
    temperature=0.7,
    max_tokens=200,
):
    sys.stdout.write(chunk.content)
    sys.stdout.flush()
```
```output
Woof! ğŸ¾ How can I help you today? Want to play fetch or maybe go for a walk ğŸ¶ğŸ¦´
```

### å·¥å…·/å‡½æ•°è°ƒç”¨

LangChain PremAI æ”¯æŒå·¥å…·/å‡½æ•°è°ƒç”¨ã€‚å·¥å…·/å‡½æ•°è°ƒç”¨å…è®¸æ¨¡å‹é€šè¿‡ç”Ÿæˆä¸ç”¨æˆ·å®šä¹‰çš„æ¨¡å¼ç›¸åŒ¹é…çš„è¾“å‡ºï¼Œæ¥å“åº”ç»™å®šçš„æç¤ºã€‚

- æ‚¨å¯ä»¥åœ¨ [æˆ‘ä»¬çš„æ–‡æ¡£ä¸­è¯¦ç»†äº†è§£å·¥å…·è°ƒç”¨](https://docs.premai.io/get-started/function-calling)ã€‚
- æ‚¨å¯ä»¥åœ¨ [æ–‡æ¡£çš„è¿™ä¸€éƒ¨åˆ†](https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling) ä¸­äº†è§£æ›´å¤šå…³äº langchain å·¥å…·è°ƒç”¨çš„ä¿¡æ¯ã€‚

**æ³¨æ„ï¼š**
å½“å‰ç‰ˆæœ¬çš„ LangChain ChatPremAI ä¸æ”¯æŒå¸¦æœ‰æµå¼æ”¯æŒçš„å‡½æ•°/å·¥å…·è°ƒç”¨ã€‚æµå¼æ”¯æŒå’Œå‡½æ•°è°ƒç”¨å°†å¾ˆå¿«æ¨å‡ºã€‚

#### å°†å·¥å…·ä¼ é€’ç»™æ¨¡å‹

ä¸ºäº†ä¼ é€’å·¥å…·å¹¶è®© LLM é€‰æ‹©å®ƒéœ€è¦è°ƒç”¨çš„å·¥å…·ï¼Œæˆ‘ä»¬éœ€è¦ä¼ é€’ä¸€ä¸ªå·¥å…·æ¨¡å¼ã€‚å·¥å…·æ¨¡å¼æ˜¯å‡½æ•°å®šä¹‰ä»¥åŠå…³äºå‡½æ•°çš„ä½œç”¨ã€å‡½æ•°æ¯ä¸ªå‚æ•°æ˜¯ä»€ä¹ˆç­‰çš„é€‚å½“æ–‡æ¡£å­—ç¬¦ä¸²ã€‚ä¸‹é¢æ˜¯ä¸€äº›ç®€å•çš„ç®—æœ¯å‡½æ•°åŠå…¶æ¨¡å¼ã€‚

**æ³¨æ„ï¼š** åœ¨å®šä¹‰å‡½æ•°/å·¥å…·æ¨¡å¼æ—¶ï¼Œä¸è¦å¿˜è®°æ·»åŠ æœ‰å…³å‡½æ•°å‚æ•°çš„ä¿¡æ¯ï¼Œå¦åˆ™ä¼šæŠ›å‡ºé”™è¯¯ã€‚

```python
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.tools import tool


# å®šä¹‰å‡½æ•°å‚æ•°çš„æ¨¡å¼
class OperationInput(BaseModel):
    a: int = Field(description="ç¬¬ä¸€ä¸ªæ•°å­—")
    b: int = Field(description="ç¬¬äºŒä¸ªæ•°å­—")


# ç°åœ¨å®šä¹‰å‡½æ•°ï¼Œå‚æ•°çš„æ¨¡å¼å°†æ˜¯ OperationInput
@tool("add", args_schema=OperationInput, return_direct=True)
def add(a: int, b: int) -> int:
    """å°† a å’Œ b ç›¸åŠ ã€‚

    å‚æ•°ï¼š
        a: ç¬¬ä¸€ä¸ªæ•´æ•°
        b: ç¬¬äºŒä¸ªæ•´æ•°
    """
    return a + b


@tool("multiply", args_schema=OperationInput, return_direct=True)
def multiply(a: int, b: int) -> int:
    """å°† a å’Œ b ç›¸ä¹˜ã€‚

    å‚æ•°ï¼š
        a: ç¬¬ä¸€ä¸ªæ•´æ•°
        b: ç¬¬äºŒä¸ªæ•´æ•°
    """
    return a * b
```

#### å°†å·¥å…·æ¨¡å¼ç»‘å®šåˆ°æˆ‘ä»¬çš„ LLM

æˆ‘ä»¬å°†ä½¿ç”¨ `bind_tools` æ–¹æ³•å°†ä¸Šè¿°å‡½æ•°è½¬æ¢ä¸ºâ€œå·¥å…·â€ï¼Œå¹¶å°†å…¶ä¸æ¨¡å‹ç»‘å®šã€‚è¿™æ„å‘³ç€æ¯æ¬¡è°ƒç”¨æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬éƒ½å°†ä¼ é€’è¿™äº›å·¥å…·ä¿¡æ¯ã€‚

```python
tools = [add, multiply]
llm_with_tools = chat.bind_tools(tools)
```

ä¹‹åï¼Œæˆ‘ä»¬ä»ç°åœ¨ä¸å·¥å…·ç»‘å®šçš„æ¨¡å‹ä¸­è·å–å“åº”ã€‚

```python
query = "3 * 12 ç­‰äºå¤šå°‘ï¼Ÿå¦å¤–ï¼Œ11 + 49 ç­‰äºå¤šå°‘ï¼Ÿ"

messages = [HumanMessage(query)]
ai_msg = llm_with_tools.invoke(messages)
```

æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œå½“æˆ‘ä»¬çš„èŠå¤©æ¨¡å‹ä¸å·¥å…·ç»‘å®šæ—¶ï¼Œæ ¹æ®ç»™å®šçš„æç¤ºï¼Œå®ƒä¼šè°ƒç”¨æ­£ç¡®çš„ä¸€ç»„å·¥å…·ï¼Œå¹¶æŒ‰é¡ºåºè¿›è¡Œè°ƒç”¨ã€‚

```python
ai_msg.tool_calls
```

```output
[{'name': 'multiply',
  'args': {'a': 3, 'b': 12},
  'id': 'call_A9FL20u12lz6TpOLaiS6rFa8'},
 {'name': 'add',
  'args': {'a': 11, 'b': 49},
  'id': 'call_MPKYGLHbf39csJIyb5BZ9xIk'}]
```

æˆ‘ä»¬å°†ä¸Šè¿°æ¶ˆæ¯é™„åŠ åˆ° LLMï¼Œè¿™ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œä½¿ LLM çŸ¥é“å®ƒè°ƒç”¨äº†å“ªäº›å‡½æ•°ã€‚

```python
messages.append(ai_msg)
```

ç”±äºå·¥å…·è°ƒç”¨åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼Œå…¶ä¸­ï¼š

1. åœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨ä¸­ï¼Œæˆ‘ä»¬æ”¶é›†äº† LLM å†³å®šä½¿ç”¨çš„æ‰€æœ‰å·¥å…·ï¼Œä»¥ä¾¿å®ƒå¯ä»¥å°†ç»“æœä½œä¸ºé™„åŠ ä¸Šä¸‹æ–‡ï¼Œä»è€Œæä¾›æ›´å‡†ç¡®ä¸”æ— å¹»è§‰çš„ç»“æœã€‚

2. åœ¨ç¬¬äºŒæ¬¡è°ƒç”¨ä¸­ï¼Œæˆ‘ä»¬å°†è§£æ LLM å†³å®šçš„é‚£ç»„å·¥å…·å¹¶è¿è¡Œå®ƒä»¬ï¼ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œè¿™å°†æ˜¯æˆ‘ä»¬å®šä¹‰çš„å‡½æ•°ï¼Œä½¿ç”¨ LLM æå–çš„å‚æ•°ï¼‰ï¼Œå¹¶å°†æ­¤ç»“æœä¼ é€’ç»™ LLMã€‚

```python
from langchain_core.messages import ToolMessage

for tool_call in ai_msg.tool_calls:
    selected_tool = {"add": add, "multiply": multiply}[tool_call["name"].lower()]
    tool_output = selected_tool.invoke(tool_call["args"])
    messages.append(ToolMessage(tool_output, tool_call_id=tool_call["id"]))
```

æœ€åï¼Œæˆ‘ä»¬è°ƒç”¨ä¸å·¥å…·ç»‘å®šçš„ LLMï¼Œå¹¶å°†å‡½æ•°å“åº”æ·»åŠ åˆ°å…¶ä¸Šä¸‹æ–‡ä¸­ã€‚

```python
response = llm_with_tools.invoke(messages)
print(response.content)
```
```output
æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼š

- 3 * 12 = 36
- 11 + 49 = 60
```

### å®šä¹‰å·¥å…·æ¨¡å¼ï¼šPydantic ç±»

ä¸Šé¢æˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ `tool` è£…é¥°å™¨å®šä¹‰æ¨¡å¼ï¼Œä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨ Pydantic ç­‰æ•ˆåœ°å®šä¹‰æ¨¡å¼ã€‚å½“ä½ çš„å·¥å…·è¾“å…¥æ›´å¤æ‚æ—¶ï¼ŒPydantic éå¸¸æœ‰ç”¨ï¼š

```python
from langchain_core.output_parsers.openai_tools import PydanticToolsParser


class add(BaseModel):
    """å°†ä¸¤ä¸ªæ•´æ•°ç›¸åŠ ã€‚"""

    a: int = Field(..., description="ç¬¬ä¸€ä¸ªæ•´æ•°")
    b: int = Field(..., description="ç¬¬äºŒä¸ªæ•´æ•°")


class multiply(BaseModel):
    """å°†ä¸¤ä¸ªæ•´æ•°ç›¸ä¹˜ã€‚"""

    a: int = Field(..., description="ç¬¬ä¸€ä¸ªæ•´æ•°")
    b: int = Field(..., description="ç¬¬äºŒä¸ªæ•´æ•°")


tools = [add, multiply]
```

ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥å°†å®ƒä»¬ç»‘å®šåˆ°èŠå¤©æ¨¡å‹ï¼Œå¹¶ç›´æ¥è·å¾—ç»“æœï¼š

```python
chain = llm_with_tools | PydanticToolsParser(tools=[multiply, add])
chain.invoke(query)
```



```output
[multiply(a=3, b=12), add(a=11, b=49)]
```


ç°åœ¨ï¼Œåƒä¸Šé¢é‚£æ ·ï¼Œæˆ‘ä»¬è§£æè¿™ä¸ªå¹¶è¿è¡Œè¿™äº›å‡½æ•°ï¼Œå†æ¬¡è°ƒç”¨ LLM ä»¥è·å¾—ç»“æœã€‚

## ç›¸å…³

- èŠå¤©æ¨¡å‹ [æ¦‚å¿µæŒ‡å—](/docs/concepts/#chat-models)
- èŠå¤©æ¨¡å‹ [æ“ä½œæŒ‡å—](/docs/how_to/#chat-models)