---
sidebar_position: 1
sidebar_class_name: hidden
keywords: [兼容性]
custom_edit_url:
---

# LLMs

:::info

如果您想自己编写 LLM，请参见 [此指南](/docs/how_to/custom_llm/)。  
如果您想贡献一个集成，请参见 [贡献集成](/docs/contributing/integrations/)。

:::

## 特性（原生支持）
所有 LLM 都实现了 Runnable 接口，该接口提供了所有方法的默认实现，即 `ainvoke`、`batch`、`abatch`、`stream`、`astream`。这使得所有 LLM 对异步、流式和批处理提供了基本支持，默认实现如下：
- *异步* 支持默认调用 asyncio 的默认线程池执行器中的相应同步方法。这允许您应用程序中的其他异步函数在 LLM 执行时继续进展，通过将此调用移至后台线程。
- *流式* 支持默认返回一个 `Iterator`（在异步流式情况下为 `AsyncIterator`），其单个值为底层 LLM 提供者返回的最终结果。这显然不能提供逐个令牌的流式支持，这需要 LLM 提供者的原生支持，但确保期望令牌迭代器的代码可以在我们的任何 LLM 集成中正常工作。
- *批处理* 支持默认通过使用线程池执行器（在同步批处理情况下）或 `asyncio.gather`（在异步批处理情况下）并行调用底层 LLM 处理每个输入。并发性可以通过 `RunnableConfig` 中的 `max_concurrency` 键进行控制。

每个 LLM 集成可以选择性地提供异步、流式或批处理的原生实现，对于支持它的提供者，这可能更有效。下表显示了每个集成的特性及其原生支持情况。

模型|调用|异步调用|流式|异步流式|批处理|异步批处理
:-|:-:|:-:|:-:|:-:|:-:|:-:
AI21|✅|❌|❌|❌|❌|❌
AlephAlpha|✅|❌|❌|❌|❌|❌
AmazonAPIGateway|✅|❌|❌|❌|❌|❌
Anthropic|✅|✅|✅|✅|❌|❌
Anyscale|✅|✅|✅|✅|✅|✅
Aphrodite|✅|❌|❌|❌|✅|❌
Arcee|✅|❌|❌|❌|❌|❌
Aviary|✅|❌|❌|❌|❌|❌
AzureMLOnlineEndpoint|✅|❌|❌|❌|✅|❌
AzureOpenAI|✅|✅|✅|✅|✅|✅
BaichuanLLM|✅|❌|❌|❌|❌|❌
Banana|✅|❌|❌|❌|❌|❌
Baseten|✅|❌|❌|❌|❌|❌
Beam|✅|❌|❌|❌|❌|❌
Bedrock|✅|✅|✅|✅|❌|❌
CTransformers|✅|✅|❌|❌|❌|❌
CTranslate2|✅|❌|❌|❌|✅|❌
CerebriumAI|✅|❌|❌|❌|❌|❌
ChatGLM|✅|❌|❌|❌|❌|❌
Clarifai|✅|❌|❌|❌|❌|❌
Cohere|✅|✅|❌|❌|❌|❌
Databricks|✅|❌|❌|❌|❌|❌
DeepInfra|✅|✅|✅|✅|❌|❌
DeepSparse|✅|✅|✅|✅|❌|❌
EdenAI|✅|✅|❌|❌|❌|❌
Fireworks|✅|✅|✅|✅|✅|✅
ForefrontAI|✅|❌|❌|❌|❌|❌
Friendli|✅|✅|✅|✅|❌|❌
GPT4All|✅|❌|❌|❌|❌|❌
GigaChat|✅|✅|✅|✅|✅|✅
GooglePalm|✅|❌|✅|❌|✅|❌
GooseAI|✅|❌|❌|❌|❌|❌
GradientLLM|✅|✅|❌|❌|✅|✅
HuggingFaceEndpoint|✅|✅|✅|✅|❌|❌
HuggingFaceHub|✅|❌|❌|❌|❌|❌
HuggingFacePipeline|✅|❌|✅|❌|✅|❌
HuggingFaceTextGenInference|✅|✅|✅|✅|❌|❌
HumanInputLLM|✅|❌|❌|❌|❌|❌
IpexLLM|✅|❌|❌|❌|❌|❌
JavelinAIGateway|✅|✅|❌|❌|❌|❌
KoboldApiLLM|✅|❌|❌|❌|❌|❌
Konko|✅|✅|❌|❌|❌|❌
LlamaCpp|✅|❌|✅|❌|❌|❌
Llamafile|✅|❌|✅|❌|❌|❌
MLXPipeline|✅|❌|✅|❌|❌|❌
ManifestWrapper|✅|❌|❌|❌|❌|❌
Minimax|✅|❌|❌|❌|❌|❌
Mlflow|✅|❌|❌|❌|❌|❌
MlflowAIGateway|✅|❌|❌|❌|❌|❌
Modal|✅|❌|❌|❌|❌|❌
MosaicML|✅|❌|❌|❌|❌|❌
NIBittensorLLM|✅|❌|❌|❌|❌|❌
NLPCloud|✅|❌|❌|❌|❌|❌
Nebula|✅|❌|❌|❌|❌|❌
OCIGenAI|✅|❌|✅|❌|❌|❌
OCIModelDeploymentTGI|✅|❌|❌|❌|❌|❌
OCIModelDeploymentVLLM|✅|❌|❌|❌|❌|❌
OctoAIEndpoint|✅|✅|✅|✅|✅|✅
Ollama|✅|❌|❌|❌|❌|❌
OpaquePrompts|✅|❌|❌|❌|❌|❌
OpenAI|✅|✅|✅|✅|✅|✅
OpenLLM|✅|✅|❌|❌|❌|❌
OpenLM|✅|✅|✅|✅|✅|✅
PaiEasEndpoint|✅|❌|✅|❌|❌|❌
Petals|✅|❌|❌|❌|❌|❌
PipelineAI|✅|❌|❌|❌|❌|❌
Predibase|✅|❌|❌|❌|❌|❌
PredictionGuard|✅|❌|❌|❌|❌|❌
PromptLayerOpenAI|✅|❌|❌|❌|❌|❌
QianfanLLMEndpoint|✅|✅|✅|✅|❌|❌
RWKV|✅|❌|❌|❌|❌|❌
Replicate|✅|❌|✅|❌|❌|❌
SagemakerEndpoint|✅|❌|❌|❌|❌|❌
SambaStudio|✅|❌|✅|❌|❌|❌
Sambaverse|✅|❌|✅|❌|❌|❌
SelfHostedHuggingFaceLLM|✅|❌|❌|❌|❌|❌
SelfHostedPipeline|✅|❌|❌|❌|❌|❌
SparkLLM|✅|❌|✅|❌|❌|❌
StochasticAI|✅|❌|❌|❌|❌|❌
TextGen|✅|❌|❌|❌|❌|❌
TitanTakeoff|✅|❌|✅|❌|❌|❌
TitanTakeoffPro|✅|❌|✅|❌|❌|❌
Together|✅|✅|❌|❌|❌|❌
Tongyi|✅|✅|✅|✅|✅|✅
VLLM|✅|❌|❌|❌|✅|❌
VLLMOpenAI|✅|✅|✅|✅|✅|✅
VertexAI|✅|✅|✅|❌|✅|✅
VertexAIModelGarden|✅|✅|❌|❌|✅|✅
VolcEngineMaasLLM|✅|❌|✅|❌|❌|❌
WatsonxLLM|✅|❌|✅|❌|✅|❌
WeightOnlyQuantPipeline|✅|❌|❌|❌|❌|❌
Writer|✅|❌|❌|❌|❌|❌
Xinference|✅|❌|❌|❌|❌|❌
YandexGPT|✅|✅|❌|❌|❌|❌
YiLLM|✅|❌|❌|❌|❌|❌
You|✅|❌|✅|❌|❌|❌
Yuan2|✅|❌|❌|❌|❌|❌