# DeepInfra

>[DeepInfra](https://deepinfra.com/docs) 使我们能够轻松运行 
> [最新的机器学习模型](https://deepinfra.com/models)。 
> DeepInfra 处理与运行、扩展和监控模型相关的所有繁重工作。用户可以专注于您的应用程序，并通过简单的 REST API 调用集成模型。

>DeepInfra 提供与 LangChain 集成的 [示例](https://deepinfra.com/docs/advanced/langchain)。

本页面介绍如何在 `LangChain` 中使用 `DeepInfra` 生态系统。
它分为两个部分：安装和设置，然后引用特定的 DeepInfra 包装器。

## 安装和设置

- 从此链接获取您的 DeepInfra api 密钥 [here](https://deepinfra.com/)。
- 获取一个 DeepInfra api 密钥并将其设置为环境变量 (`DEEPINFRA_API_TOKEN`)

## 可用模型

DeepInfra 提供了一系列可供部署的开源 LLM。

您可以查看支持的模型
[text-generation](https://deepinfra.com/models?type=text-generation) 和
[embeddings](https://deepinfra.com/models?type=embeddings)。

您可以查看 [请求和响应参数的列表](https://deepinfra.com/meta-llama/Llama-2-70b-chat-hf/api)。

聊天模型 [遵循 openai api](https://deepinfra.com/meta-llama/Llama-2-70b-chat-hf/api?example=openai-http)

## LLM

请参见[使用示例](/docs/integrations/llms/deepinfra)。

```python
from langchain_community.llms import DeepInfra
```

## 嵌入

请参见[使用示例](/docs/integrations/text_embedding/deepinfra)。

```python
from langchain_community.embeddings import DeepInfraEmbeddings
```

## 聊天模型

查看[使用示例](/docs/integrations/chat/deepinfra)。

```python
from langchain_community.chat_models import ChatDeepInfra
```