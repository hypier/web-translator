# Intel

>[Optimum Intel](https://github.com/huggingface/optimum-intel?tab=readme-ov-file#optimum-intel) æ˜¯ ğŸ¤— Transformers å’Œ Diffusers åº“ä¸ Intel æä¾›çš„ä¸åŒå·¥å…·å’Œåº“ä¹‹é—´çš„æ¥å£ï¼Œä»¥åŠ é€Ÿåœ¨ Intel æ¶æ„ä¸Šçš„ç«¯åˆ°ç«¯ç®¡é“ã€‚

>[IntelÂ® Extension for Transformers](https://github.com/intel/intel-extension-for-transformers?tab=readme-ov-file#intel-extension-for-transformers) (ITREX) æ˜¯ä¸€ä¸ªåˆ›æ–°å·¥å…·åŒ…ï¼Œæ—¨åœ¨ä»¥æœ€ä½³æ€§èƒ½åŠ é€Ÿå„ç§ Intel å¹³å°ä¸ŠåŸºäº Transformer çš„æ¨¡å‹çš„ GenAI/LLMï¼ŒåŒ…æ‹¬ Intel Gaudi2ã€Intel CPU å’Œ Intel GPUã€‚

æœ¬é¡µé¢ä»‹ç»å¦‚ä½•å°† optimum-intel å’Œ ITREX ä¸ LangChain ä¸€èµ·ä½¿ç”¨ã€‚

## Optimum-intel

ä¸ [optimum-intel](https://github.com/huggingface/optimum-intel.git) å’Œ [IPEX](https://github.com/intel/intel-extension-for-pytorch) ç›¸å…³çš„æ‰€æœ‰åŠŸèƒ½ã€‚

### å®‰è£…

ä½¿ç”¨ optimum-intel å’Œ ipex å®‰è£…ï¼š

```bash
pip install optimum[neural-compressor]
pip install intel_extension_for_pytorch
```

è¯·æŒ‰ç…§ä»¥ä¸‹æŒ‡å®šçš„å®‰è£…è¯´æ˜è¿›è¡Œæ“ä½œï¼š

* æŒ‰ç…§ [è¿™é‡Œ](https://github.com/huggingface/optimum-intel) æ‰€ç¤ºå®‰è£… optimum-intelã€‚
* æŒ‰ç…§ [è¿™é‡Œ](https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=cpu&version=v2.2.0%2Bcpu) æ‰€ç¤ºå®‰è£… IPEXã€‚

### åµŒå…¥æ¨¡å‹

è¯·å‚é˜… [ç”¨æ³•ç¤ºä¾‹](/docs/integrations/text_embedding/optimum_intel)ã€‚  
æˆ‘ä»¬è¿˜åœ¨é£Ÿè°±ç›®å½•ä¸­æä¾›äº†å®Œæ•´çš„æ•™ç¨‹ç¬”è®°æœ¬ "rag_with_quantized_embeddings.ipynb"ï¼Œç”¨äºåœ¨ RAG ç®¡é“ä¸­ä½¿ç”¨åµŒå…¥å™¨ã€‚

```python
from langchain_community.embeddings import QuantizedBiEncoderEmbeddings
```

## IntelÂ® Extension for Transformers (ITREX)
(ITREX) æ˜¯ä¸€ä¸ªåˆ›æ–°å·¥å…·åŒ…ï¼Œç”¨äºåŠ é€ŸåŸºäº Transformer çš„æ¨¡å‹åœ¨ Intel å¹³å°ä¸Šçš„è¿è¡Œï¼Œç‰¹åˆ«æ˜¯åœ¨ç¬¬ 4 ä»£ Intel Xeon å¯æ‰©å±•å¤„ç†å™¨ Sapphire Rapidsï¼ˆä»£å· Sapphire Rapidsï¼‰ä¸Šè¡¨ç°å“è¶Šã€‚

é‡åŒ–æ˜¯ä¸€ä¸ªé€šè¿‡ä½¿ç”¨æ›´å°‘çš„ä½æ•°æ¥è¡¨ç¤ºè¿™äº›æƒé‡ï¼Œä»è€Œé™ä½å…¶ç²¾åº¦çš„è¿‡ç¨‹ã€‚ä»…æƒé‡é‡åŒ–ä¸“æ³¨äºå¯¹ç¥ç»ç½‘ç»œçš„æƒé‡è¿›è¡Œé‡åŒ–ï¼ŒåŒæ—¶ä¿æŒå…¶ä»–ç»„ä»¶ï¼ˆå¦‚æ¿€æ´»ï¼‰åœ¨å…¶åŸå§‹ç²¾åº¦ä¸‹ã€‚

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ—¥ç›Šæ™®åŠï¼Œå¯¹æ–°å‹å’Œæ”¹è¿›çš„é‡åŒ–æ–¹æ³•çš„éœ€æ±‚ä¸æ–­å¢åŠ ï¼Œè¿™äº›æ–¹æ³•èƒ½å¤Ÿæ»¡è¶³ç°ä»£æ¶æ„çš„è®¡ç®—éœ€æ±‚ï¼ŒåŒæ—¶ä¿æŒå‡†ç¡®æ€§ã€‚ä¸ [æ™®é€šé‡åŒ–](https://github.com/intel/intel-extension-for-transformers/blob/main/docs/quantization.md)ï¼ˆå¦‚ W8A8ï¼‰ç›¸æ¯”ï¼Œä»…æƒé‡é‡åŒ–å¯èƒ½æ˜¯å¹³è¡¡æ€§èƒ½å’Œå‡†ç¡®æ€§çš„æ›´å¥½æŠ˜è¡·ï¼Œå› ä¸ºæˆ‘ä»¬å°†åœ¨ä¸‹é¢çœ‹åˆ°ï¼Œéƒ¨ç½² LLM çš„ç“¶é¢ˆæ˜¯å†…å­˜å¸¦å®½ï¼Œè€Œé€šå¸¸ä»…æƒé‡é‡åŒ–å¯ä»¥å¯¼è‡´æ›´å¥½çš„å‡†ç¡®æ€§ã€‚

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä»‹ç» ITREX ä¸­çš„åµŒå…¥æ¨¡å‹å’Œä»…æƒé‡é‡åŒ–ï¼Œç”¨äº Transformers å¤§å‹è¯­è¨€æ¨¡å‹ã€‚ä»…æƒé‡é‡åŒ–æ˜¯ä¸€ç§ç”¨äºæ·±åº¦å­¦ä¹ çš„æŠ€æœ¯ï¼Œç”¨äºå‡å°‘ç¥ç»ç½‘ç»œçš„å†…å­˜å’Œè®¡ç®—éœ€æ±‚ã€‚åœ¨æ·±åº¦ç¥ç»ç½‘ç»œçš„ä¸Šä¸‹æ–‡ä¸­ï¼Œæ¨¡å‹å‚æ•°ï¼Œä¹Ÿç§°ä¸ºæƒé‡ï¼Œé€šå¸¸ä½¿ç”¨æµ®ç‚¹æ•°è¡¨ç¤ºï¼Œè¿™å¯èƒ½ä¼šæ¶ˆè€—å¤§é‡å†…å­˜å¹¶éœ€è¦å¤§é‡è®¡ç®—èµ„æºã€‚

æ‰€æœ‰ä¸ [intel-extension-for-transformers](https://github.com/intel/intel-extension-for-transformers) ç›¸å…³çš„åŠŸèƒ½ã€‚

### å®‰è£…

å®‰è£… intel-extension-for-transformersã€‚æœ‰å…³ç³»ç»Ÿè¦æ±‚å’Œå…¶ä»–å®‰è£…æç¤ºï¼Œè¯·å‚é˜… [å®‰è£…æŒ‡å—](https://github.com/intel/intel-extension-for-transformers/blob/main/docs/installation.md)

```bash
pip install intel-extension-for-transformers
```
å®‰è£…å…¶ä»–æ‰€éœ€çš„åŒ…ã€‚

```bash
pip install -U torch onnx accelerate datasets
```

### åµŒå…¥æ¨¡å‹

æŸ¥çœ‹[ä½¿ç”¨ç¤ºä¾‹](/docs/integrations/text_embedding/itrex)ã€‚

```python
from langchain_community.embeddings import QuantizedBgeEmbeddings
```

### ä»…æƒé‡é‡åŒ–ä¸ ITREX

è¯·å‚é˜… [ä½¿ç”¨ç¤ºä¾‹](/docs/integrations/llms/weight_only_quantization)ã€‚

## é…ç½®å‚æ•°ç»†èŠ‚

ä»¥ä¸‹æ˜¯ `WeightOnlyQuantConfig` ç±»çš„è¯¦ç»†ä¿¡æ¯ã€‚

#### weight_dtype (string): æƒé‡æ•°æ®ç±»å‹ï¼Œé»˜è®¤å€¼ä¸º "nf4"ã€‚
æˆ‘ä»¬æ”¯æŒå°†æƒé‡é‡åŒ–ä¸ºä»¥ä¸‹æ•°æ®ç±»å‹ä»¥è¿›è¡Œå­˜å‚¨ï¼ˆWeightOnlyQuantConfig ä¸­çš„ weight_dtypeï¼‰ï¼š
* **int8**: ä½¿ç”¨ 8 ä½æ•°æ®ç±»å‹ã€‚
* **int4_fullrange**: ä½¿ç”¨ int4 èŒƒå›´çš„ -8 å€¼ï¼Œä¸æ­£å¸¸çš„ int4 èŒƒå›´ [-7,7] ç›¸æ¯”ã€‚
* **int4_clip**: è£å‰ªå¹¶ä¿ç•™ int4 èŒƒå›´å†…çš„å€¼ï¼Œå°†å…¶ä»–å€¼è®¾ä¸ºé›¶ã€‚
* **nf4**: ä½¿ç”¨è§„èŒƒåŒ–çš„ 4 ä½æµ®ç‚¹æ•°æ®ç±»å‹ã€‚
* **fp4_e2m1**: ä½¿ç”¨å¸¸è§„çš„ 4 ä½æµ®ç‚¹æ•°æ®ç±»å‹ã€‚"e2" è¡¨ç¤º 2 ä½ç”¨äºæŒ‡æ•°ï¼Œ"m1" è¡¨ç¤º 1 ä½ç”¨äºå°¾æ•°ã€‚

#### compute_dtype (string): è®¡ç®—æ•°æ®ç±»å‹ï¼Œé»˜è®¤å€¼ä¸º "fp32"ã€‚
è™½ç„¶è¿™äº›æŠ€æœ¯å°†æƒé‡å­˜å‚¨ä¸º 4 ä½æˆ– 8 ä½ï¼Œä½†è®¡ç®—ä»ç„¶å‘ç”Ÿåœ¨ float32ã€bfloat16 æˆ– int8ï¼ˆWeightOnlyQuantConfig ä¸­çš„ compute_dtypeï¼‰ï¼š
* **fp32**: ä½¿ç”¨ float32 æ•°æ®ç±»å‹è¿›è¡Œè®¡ç®—ã€‚
* **bf16**: ä½¿ç”¨ bfloat16 æ•°æ®ç±»å‹è¿›è¡Œè®¡ç®—ã€‚
* **int8**: ä½¿ç”¨ 8 ä½æ•°æ®ç±»å‹è¿›è¡Œè®¡ç®—ã€‚

#### llm_int8_skip_modules (list of module's name): è·³è¿‡é‡åŒ–çš„æ¨¡å—ï¼Œé»˜è®¤å€¼ä¸º Noneã€‚
è¿™æ˜¯ä¸€ä¸ªè¦è·³è¿‡é‡åŒ–çš„æ¨¡å—åˆ—è¡¨ã€‚

#### scale_dtype (string): ç¼©æ”¾æ•°æ®ç±»å‹ï¼Œé»˜è®¤å€¼ä¸º "fp32"ã€‚
ç›®å‰ä»…æ”¯æŒ "fp32"ï¼ˆfloat32ï¼‰ã€‚

#### mse_range (boolean): æ˜¯å¦ä»èŒƒå›´ [0.805, 1.0, 0.005] ä¸­æœç´¢æœ€ä½³è£å‰ªèŒƒå›´ï¼Œé»˜è®¤å€¼ä¸º Falseã€‚
#### use_double_quant (boolean): æ˜¯å¦é‡åŒ–ç¼©æ”¾ï¼Œé»˜è®¤å€¼ä¸º Falseã€‚
å°šä¸æ”¯æŒã€‚
#### double_quant_dtype (string): ä¿ç•™ç”¨äºåŒé‡é‡åŒ–ã€‚
#### double_quant_scale_dtype (string): ä¿ç•™ç”¨äºåŒé‡é‡åŒ–ã€‚
#### group_size (int): é‡åŒ–æ—¶çš„ç»„å¤§å°ã€‚
#### scheme (string): æƒé‡é‡åŒ–çš„æ ¼å¼ã€‚é»˜è®¤å€¼ä¸º "sym"ã€‚
* **sym**: å¯¹ç§°ã€‚
* **asym**: éå¯¹ç§°ã€‚
#### algorithm (string): ç”¨äºæé«˜å‡†ç¡®æ€§çš„ç®—æ³•ã€‚é»˜è®¤å€¼ä¸º "RTN"ã€‚
* **RTN**: æœ€è¿‘é‚»èˆå…¥ (RTN) æ˜¯ä¸€ç§æˆ‘ä»¬å¯ä»¥éå¸¸ç›´è§‚ç†è§£çš„é‡åŒ–æ–¹æ³•ã€‚
* **AWQ**: ä»…ä¿æŠ¤ 1% çš„æ˜¾è‘—æƒé‡å¯ä»¥å¤§å¤§å‡å°‘é‡åŒ–è¯¯å·®ã€‚æ˜¾è‘—æƒé‡é€šé“æ˜¯é€šè¿‡è§‚å¯Ÿæ¯ä¸ªé€šé“çš„æ¿€æ´»å’Œæƒé‡åˆ†å¸ƒæ¥é€‰æ‹©çš„ã€‚æ˜¾è‘—æƒé‡åœ¨é‡åŒ–å‰åœ¨ä¹˜ä»¥ä¸€ä¸ªå¤§ç¼©æ”¾å› å­åä¹Ÿä¼šè¢«é‡åŒ–ä»¥è¿›è¡Œä¿ç•™ã€‚
* **TEQ**: ä¸€ç§å¯è®­ç»ƒçš„ç­‰æ•ˆå˜æ¢ï¼Œåœ¨ä»…æƒé‡é‡åŒ–ä¸­ä¿ç•™ FP32 ç²¾åº¦ã€‚