---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/integrations/document_loaders/docusaurus.ipynb
---

# Docusaurus
> [Docusaurus](https://docusaurus.io/) 是一个静态网站生成器，提供开箱即用的文档功能。

通过利用现有的 `SitemapLoader`，该加载器扫描并加载给定 Docusaurus 应用中的所有页面，并将每个页面的主要文档内容作为文档返回。

```python
from langchain_community.document_loaders import DocusaurusLoader
```

安装必要的依赖

```python
%pip install --upgrade --quiet beautifulsoup4 lxml
```

```python
# 修复 asyncio 和 jupyter 的一个 bug
import nest_asyncio

nest_asyncio.apply()
```

```python
loader = DocusaurusLoader("https://python.langchain.com")

docs = loader.load()
```
```output
Fetching pages: 100%|##########| 939/939 [01:19<00:00, 11.85it/s]
```
> `SitemapLoader` 还提供了利用和调整并发性的能力，这可以帮助优化加载源文档所需的时间。有关更多信息，请参阅 [sitemap docs](/docs/integrations/document_loaders/sitemap)。

```python
docs[0]
```

```output
Document(page_content="\n\n\n\n\nCookbook | 🦜️🔗 Langchain\n\n\n\n\n\n\nSkip to main content🦜️🔗 LangChainDocsUse casesIntegrationsAPICommunityChat our docsLangSmithJS/TS DocsSearchCTRLKCookbookThe page you're looking for has been moved to the cookbook section of the repo as a notebook.CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright © 2023 LangChain, Inc.\n\n\n\n", metadata={'source': 'https://python.langchain.com/cookbook', 'loc': 'https://python.langchain.com/cookbook', 'changefreq': 'weekly', 'priority': '0.5'})
```

## 过滤网站地图 URLs

网站地图可能包含成千上万个 URL，通常并不是每一个都需要。您可以通过将字符串或正则表达式模式的列表传递给 `url_filter` 参数来过滤 URLs。只有匹配某个模式的 URL 才会被加载。

```python
loader = DocusaurusLoader(
    "https://python.langchain.com",
    filter_urls=[
        "https://python.langchain.com/docs/integrations/document_loaders/sitemap"
    ],
)
documents = loader.load()
```
```output
Fetching pages: 100%|##########| 1/1 [00:00<00:00,  5.21it/s]
```

```python
documents[0]
```

```output
Document(page_content='\n\n\n\n\nSitemap | 🦜️🔗 Langchain\n\n\n\n\n\n\nSkip to main content🦜️🔗 LangChainDocsUse casesIntegrationsAPICommunityChat our docsLangSmithJS/TS DocsSearchCTRLKProvidersAnthropicAWSGoogleMicrosoftOpenAIMoreComponentsLLMsChat modelsDocument loadersacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEtherscanEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWiki DumpMerge Documents LoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryMongoDBNews URLNotion DB 1/2Notion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySparkReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas Data FrameYouTube audioYouTube transcriptsDocument transformersText embedding modelsVector storesRetrieversToolsAgents and toolkitsMemoryCallbacksChat loadersComponentsDocument loadersSitemapOn this pageSitemapExtends from the WebBaseLoader, SitemapLoader loads a sitemap from a given URL, and then scrape and load all pages in the sitemap, returning each page as a Document.The scraping is done concurrently.  There are reasonable limits to concurrent requests, defaulting to 2 per second.  If you aren\'t concerned about being a good citizen, or you control the scrapped server, or don\'t care about load. Note, while this will speed up the scraping process, but it may cause the server to block you.  Be careful!pip install nest_asyncio    Requirement already satisfied: nest_asyncio in /Users/tasp/Code/projects/langchain/.venv/lib/python3.10/site-packages (1.5.6)        [notice] A new release of pip available: 22.3.1 -> 23.0.1    [notice] To update, run: pip install --upgrade pip# fixes a bug with asyncio and jupyterimport nest_asyncionest_asyncio.apply()from langchain_community.document_loaders.sitemap import SitemapLoadersitemap_loader = SitemapLoader(web_path="https://langchain.readthedocs.io/sitemap.xml")docs = sitemap_loader.load()You can change the requests_per_second parameter to increase the max concurrent requests. and use requests_kwargs to pass kwargs when send requests.sitemap_loader.requests_per_second = 2# Optional: avoid `[SSL: CERTIFICATE_VERIFY_FAILED]` issuesitemap_loader.requests_kwargs = {"verify": False}docs[0]    Document(page_content=\'\\n\\n\\n\\n\\n\\nWelcome to LangChain — 🦜🔗 LangChain 0.0.123\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCtrl+K\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n🦜🔗 LangChain 0.0.123\\n\\n\\n\\nGetting Started\\n\\nQuickstart Guide\\n\\nModules\\n\\nPrompt Templates\\nGetting Started\\nKey Concepts\\nHow-To Guides\\nCreate a custom prompt template\\nCreate a custom example selector\\nProvide few shot examples to a prompt\\nPrompt Serialization\\nExample Selectors\\nOutput Parsers\\n\\n\\nReference\\nPromptTemplates\\nExample Selector\\n\\n\\n\\n\\nLLMs\\nGetting Started\\nKey Concepts\\nHow-To Guides\\nGeneric Functionality\\nCustom LLM\\nFake LLM\\nLLM Caching\\nLLM Serialization\\nToken Usage Tracking\\n\\n\\nIntegrations\\nAI21\\nAleph Alpha\\nAnthropic\\nAzure OpenAI LLM Example\\nBanana\\nCerebriumAI LLM Example\\nCohere\\nDeepInfra LLM Example\\nForefrontAI LLM Example\\nGooseAI LLM Example\\nHugging Face Hub\\nManifest\\nModal\\nOpenAI\\nPetals LLM Example\\nPromptLayer OpenAI\\nSageMakerEndpoint\\nSelf-Hosted Models via Runhouse\\nStochasticAI\\nWriter\\n\\n\\nAsync API for LLM\\nStreaming with LLMs\\n\\n\\nReference\\n\\n\\nDocument Loaders\\nKey Concepts\\nHow To Guides\\nCoNLL-U\\nAirbyte JSON\\nAZLyrics\\nBlackboard\\nCollege Confidential\\nCopy Paste\\nCSV Loader\\nDirectory Loader\\nEmail\\nEverNote\\nFacebook Chat\\nFigma\\nGCS Directory\\nGCS File Storage\\nGitBook\\nGoogle Drive\\nGutenberg\\nHacker News\\nHTML\\niFixit\\nImages\\nIMSDb\\nMarkdown\\nNotebook\\nNotion\\nObsidian\\nPDF\\nPowerPoint\\nReadTheDocs Documentation\\nRoam\\ns3 Directory\\ns3 File\\nSubtitle Files\\nTelegram\\nUnstructured File Loader\\nURL\\nWeb Base\\nWord Documents\\nYouTube\\n\\n\\n\\n\\nUtils\\nKey Concepts\\nGeneric Utilities\\nBash\\nBing Search\\nGoogle Search\\nGoogle Serper API\\nIFTTT WebHooks\\nPython REPL\\nRequests\\nSearxNG Search API\\nSerpAPI\\nWolfram Alpha\\nZapier Natural Language Actions API\\n\\n\\nReference\\nPython REPL\\nSerpAPI\\nSearxNG Search\\nDocstore\\nText Splitter\\nEmbeddings\\nVectorStores\\n\\n\\n\\n\\nIndexes\\nGetting Started\\nKey Concepts\\nHow To Guides\\nEmbeddings\\nHypothetical Document Embeddings\\nText Splitter\\nVectorStores\\nAtlasDB\\nChroma\\nDeep Lake\\nElasticSearch\\nFAISS\\nMilvus\\nOpenSearch\\nPGVector\\nPinecone\\nQdrant\\nRedis\\nWeaviate\\nChatGPT Plugin Retriever\\nVectorStore Retriever\\nAnalyze Document\\nChat Index\\nGraph QA\\nQuestion Answering with Sources\\nQuestion Answering\\nSummarization\\nRetrieval Question/Answering\\nRetrieval Question Answering with Sources\\nVector DB Text Generation\\n\\n\\n\\n\\nChains\\nGetting Started\\nHow-To Guides\\nGeneric Chains\\nLoading from LangChainHub\\nLLM Chain\\nSequential Chains\\nSerialization\\nTransformation Chain\\n\\n\\nUtility Chains\\nAPI Chains\\nSelf-Critique Chain with Constitutional AI\\nBashChain\\nLLMCheckerChain\\nLLM Math\\nLLMRequestsChain\\nLLMSummarizationCheckerChain\\nModeration\\nPAL\\nSQLite example\\n\\n\\nAsync API for Chain\\n\\n\\nKey Concepts\\nReference\\n\\n\\nAgents\\nGetting Started\\nKey Concepts\\nHow-To Guides\\nAgents and Vectorstores\\nAsync API for Agent\\nConversation Agent (for Chat Models)\\nChatGPT Plugins\\nCustom Agent\\nDefining Custom Tools\\nHuman as a tool\\nIntermediate Steps\\nLoading from LangChainHub\\nMax Iterations\\nMulti Input Tools\\nSearch Tools\\nSerialization\\nAdding SharedMemory to an Agent and its Tools\\nCSV Agent\\nJSON Agent\\nOpenAPI Agent\\nPandas Dataframe Agent\\nPython Agent\\nSQL Database Agent\\nVectorstore Agent\\nMRKL\\nMRKL Chat\\nReAct\\nSelf Ask With Search\\n\\n\\nReference\\n\\n\\nMemory\\nGetting Started\\nKey Concepts\\nHow-To Guides\\nConversationBufferMemory\\nConversationBufferWindowMemory\\nEntity Memory\\nConversation Knowledge Graph Memory\\nConversationSummaryMemory\\nConversationSummaryBufferMemory\\nConversationTokenBufferMemory\\nAdding Memory To an LLMChain\\nAdding Memory to a Multi-Input Chain\\nAdding Memory to an Agent\\nChatGPT Clone\\nConversation Agent\\nConversational Memory Customization\\nCustom Memory\\nMultiple Memory\\n\\n\\n\\n\\nChat\\nGetting Started\\nKey Concepts\\nHow-To Guides\\nAgent\\nChat Vector DB\\nFew Shot Examples\\nMemory\\nPromptLayer ChatOpenAI\\nStreaming\\nRetrieval Question/Answering\\nRetrieval Question Answering with Sources\\n\\n\\n\\n\\n\\nUse Cases\\n\\nAgents\\nChatbots\\nGenerate Examples\\nData Augmented Generation\\nQuestion Answering\\nSummarization\\nQuerying Tabular Data\\nExtraction\\nEvaluation\\nAgent Benchmarking: Search + Calculator\\nAgent VectorDB Question Answering Benchmarking\\nBenchmarking Template\\nData Augmented Question Answering\\nUsing Hugging Face Datasets\\nLLM Math\\nQuestion Answering Benchmarking: Paul Graham Essay\\nQuestion Answering Benchmarking: State of the Union Address\\nQA Generation\\nQuestion Answering\\nSQL Question Answering Benchmarking: Chinook\\n\\n\\nModel Comparison\\n\\nReference\\n\\nInstallation\\nIntegrations\\nAPI References\\nPrompts\\nPromptTemplates\\nExample Selector\\n\\n\\nUtilities\\nPython REPL\\nSerpAPI\\nSearxNG Search\\nDocstore\\nText Splitter\\nEmbeddings\\nVectorStores\\n\\n\\nChains\\nAgents\\n\\n\\n\\nEcosystem\\n\\nLangChain Ecosystem\\nAI21 Labs\\nAtlasDB\\nBanana\\nCerebriumAI\\nChroma\\nCohere\\nDeepInfra\\nDeep Lake\\nForefrontAI\\nGoogle Search Wrapper\\nGoogle Serper Wrapper\\nGooseAI\\nGraphsignal\\nHazy Research\\nHelicone\\nHugging Face\\nMilvus\\nModal\\nNLPCloud\\nOpenAI\\nOpenSearch\\nPetals\\nPGVector\\nPinecone\\nPromptLayer\\nQdrant\\nRunhouse\\nSearxNG Search API\\nSerpAPI\\nStochasticAI\\nUnstructured\\nWeights & Biases\\nWeaviate\\nWolfram Alpha Wrapper\\nWriter\\n\\n\\n\\nAdditional Resources\\n\\nLangChainHub\\nGlossary\\nLangChain Gallery\\nDeployments\\nTracing\\nDiscord\\nProduction Support\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n.rst\\n\\n\\n\\n\\n\\n\\n\\n.pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWelcome to LangChain\\n\\n\\n\\n\\n Contents \\n\\n\\n\\nGetting Started\\nModules\\nUse Cases\\nReference Docs\\nLangChain Ecosystem\\nAdditional Resources\\n\\n\\n\\n\\n\\n\\n\\n\\nWelcome to LangChain#\\n大型语言模型（LLMs）作为一种变革性技术正在崛起，使开发人员能够构建他们之前无法构建的应用程序。\\n但单独使用这些 LLMs 通常不足以创建真正强大的应用程序 - 其真正的力量在于能够将它们与其他计算或知识源结合起来。\\n该库旨在协助开发这些类型的应用程序。这些类型应用程序的常见示例包括：\\n❓ 针对特定文档的问答\\n\\n文档\\n端到端示例：针对 Notion 数据库的问答\\n\\n💬 聊天机器人\\n\\n文档\\n端到端示例：Chat-LangChain\\n\\n🤖 代理\\n\\n文档\\n端到端示例：GPT+WolframAlpha\\n\\n\\n入门#\\n查看下面的指南，了解如何开始使用 LangChain 创建语言模型应用程序。\\n\\n入门文档\\n\\n\\n\\n\\n\\n模块#\\nLangChain 提供支持的几个主要模块。\\n对于每个模块，我们提供一些示例以供入门、操作指南、参考文档和概念指南。\\n这些模块按复杂程度递增：\\n\\n提示：这包括提示管理、提示优化和提示序列化。\\nLLMs：这包括所有 LLMs 的通用接口，以及处理 LLMs 的常用工具。\\n文档加载器：这包括加载文档的标准接口，以及与所有类型文本数据源的特定集成。\\n工具：当语言模型与其他知识或计算源交互时，通常更强大。这可以包括 Python REPL、嵌入、搜索引擎等。LangChain 提供了大量常用工具，供您在应用程序中使用。\\n链：链超越了单一 LLM 调用，是调用的序列（无论是对 LLM 还是其他工具）。LangChain 提供了链的标准接口、与其他工具的众多集成，以及用于常见应用程序的端到端链。\\n索引：当语言模型与您自己的文本数据结合时，通常更强大 - 本模块涵盖了实现这一目标的最佳实践。\\n代理：代理涉及 LLM 根据要采取的操作做出决策，采取该操作，查看观察结果，并重复该过程，直到完成。LangChain 提供了代理的标准接口、可供选择的代理集合以及端到端代理的示例。\\n\\n\\n\\n\\n\\n用例#\\n上述模块可以以多种方式使用。LangChain 还提供了指导和帮助。以下是 LangChain 支持的一些常见用例。\\n\\n代理：代理是使用语言模型与其他工具交互的系统。这些可以用于更扎实的问答、与 API 交互，甚至采取行动。\\n聊天机器人：由于语言模型擅长生成文本，这使得它们非常适合创建聊天机器人。\\n数据增强生成：数据增强生成涉及特定类型的链，首先与外部数据源交互，以获取用于生成步骤的数据。这包括长文本的摘要和针对特定数据源的问答。\\n问答：仅利用这些文档中的信息来回答特定文档上的问题。这是一种数据增强生成。\\n摘要：将较长的文档总结为更短、更精炼的信息块。这也是一种数据增强生成。\\n查询表格数据：如果您想了解如何使用 LLMs 查询存储在表格格式（csv、SQL、数据框等）中的数据，您应该阅读此页面。\\n评估：生成模型通常难以使用传统指标进行评估。评估它们的一种新方法是使用语言模型本身进行评估。LangChain 提供了一些提示/链来协助此过程。\\n生成类似示例：生成与给定输入相似的示例。这是许多应用程序的常见用例，LangChain 提供了一些提示/链来协助此过程。\\n比较模型：实验不同的提示、模型和链是开发最佳应用程序的重要组成部分。模型实验室使这一过程变得简单。\\n\\n\\n\\n\\n\\n参考文档#\\nLangChain 的所有参考文档，集中在一个地方。有关所有方法、类、安装方法和 LangChain 集成设置的完整文档。\\n\\n参考文档\\n\\n\\n\\n\\n\\nLangChain 生态系统#\\n有关其他公司/产品如何与 LangChain 一起使用的指南\\n\\nLangChain 生态系统\\n\\n\\n\\n\\n\\n附加资源#\\n我们认为在您开发应用程序时可能有用的附加资源集合！\\n\\nLangChainHub：LangChainHub 是一个分享和探索其他提示、链和代理的地方。\\n词汇表：所有相关术语、论文、方法等的词汇表。无论是否在 LangChain 中实现！\\n画廊：我们最喜欢的使用 LangChain 的项目集合。对于寻找灵感或查看其他应用程序中的实现方式非常有用。\\n部署：有关部署 LangChain 应用程序的说明、代码片段和模板库的集合。\\nDiscord：加入我们的 Discord，讨论与 LangChain 相关的所有内容！\\n追踪：使用 LangChain 中的追踪可视化链和代理的执行过程的指南。\\n生产支持：当您将 LangChain 转入生产时，我们希望提供更全面的支持。请填写此表格，我们将建立一个专门的支持 Slack 频道。\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n下一个\\n快速入门指南\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n 内容\\n  \\n\\n\\n入门\\n模块\\n用例\\n参考文档\\nLangChain 生态系统\\n附加资源\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n作者：Harrison Chase\\n\\n\\n\\n\\n    \\n      © 版权 2023, Harrison Chase.\\n      \\n\\n\\n\\n\\n  最后更新于 2023年3月24日。\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\', lookup_str=\'\', metadata={\'source\': \'https://python.langchain.com/en/stable/\', \'loc\': \'https://python.langchain.com/en/stable/\', \'lastmod\': \'2023-03-24T19:30:54.647430+00:00\', \'changefreq\': \'weekly\', \'priority\': \'1\'}, lookup_index=0)过滤网站地图 URLs\u200b网站地图可能是大型文件，包含成千上万个 URL。通常您并不需要每一个 URL。您可以通过将字符串或正则表达式模式的列表传递给 url_filter 参数来过滤 URLs。只有匹配某个模式的 URL 才会被加载.loader = SitemapLoader(    "https://langchain.readthedocs.io/sitemap.xml",    filter_urls=["https://python.langchain.com/en/latest/"],)documents = loader.load()documents[0]    Document(page_content=\'\\n\\n\\n\\n\\n\\n欢迎使用 LangChain — 🦜🔗 LangChain 0.0.123\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n跳转到主要内容\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCtrl+K\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n🦜🔗 LangChain 0.0.123\\n\\n\\n\\n入门\\n\\n快速入门指南\\n\\n模块\\n\\n模型\\nLLMs\\n入门\\n通用功能\\n如何使用 LLM 的异步 API\\n如何编写自定义 LLM 包装器\\n如何（以及为什么）使用假 LLM\\n如何缓存 LLM 调用\\n如何序列化 LLM 类\\n如何流式传输 LLM 响应\\n如何跟踪令牌使用\\n\\n\\n集成\\nAI21\\nAleph Alpha\\nAnthropic\\nAzure OpenAI LLM 示例\\nBanana\\nCerebriumAI LLM 示例\\nCohere\\nDeepInfra LLM 示例\\nForefrontAI LLM 示例\\nGooseAI LLM 示例\\nHugging Face Hub\\nManifest\\nModal\\nOpenAI\\nPetals LLM 示例\\nPromptLayer OpenAI\\nSageMakerEndpoint\\n通过 Runhouse 自托管模型\\nStochasticAI\\nWriter\\n\\n\\n参考\\n\\n\\n聊天模型\\n入门\\n操作指南\\n如何使用少量示例\\n如何流式传输响应\\n\\n\\n集成\\nAzure\\nOpenAI\\nPromptLayer ChatOpenAI\\n\\n\\n\\n\\n文本嵌入模型\\nAzureOpenAI\\nCohere\\n假嵌入\\nHugging Face Hub\\nInstructEmbeddings\\nOpenAI\\nSageMaker Endpoint 嵌入\\n自托管嵌入\\nTensorflowHub\\n\\n\\n\\n\\n提示\\n提示模板\\n入门\\n操作指南\\n如何创建自定义提示模板\\n如何创建使用少量示例的提示模板\\n如何处理部分提示模板\\n如何序列化提示\\n\\n\\n参考\\nPromptTemplates\\n示例选择器\\n\\n\\n\\n\\n聊天提示模板\\n示例选择器\\n如何创建自定义示例选择器\\n基于长度的示例选择器\\n最大边际相关性示例选择器\\nNGram 重叠示例选择器\\n相似性示例选择器\\n\\n\\n输出解析器\\n输出解析器\\n逗号分隔列表输出解析器\\n输出修复解析器\\nPydantic 输出解析器\\n重试输出解析器\\n结构化输出解析器\\n\\n\\n\\n\\n索引\\n入门\\n文档加载器\\nCoNLL-U\\nAirbyte JSON\\nAZLyrics\\nBlackboard\\nCollege Confidential\\n复制粘贴\\nCSV 加载器\\n目录加载器\\n电子邮件\\nEverNote\\nFacebook 聊天\\nFigma\\nGCS 目录\\nGCS 文件存储\\nGitBook\\nGoogle Drive\\nGutenberg\\nHacker News\\nHTML\\niFixit\\n图像\\nIMSDb\\nMarkdown\\n笔记本\\nNotion\\nObsidian\\nPDF\\nPowerPoint\\nReadTheDocs 文档\\nRoam\\ns3 目录\\ns3 文件\\n字幕文件\\nTelegram\\n非结构化文件加载器\\nURL\\nWeb Base\\nWord 文档\\nYouTube\\n\\n\\n文本分割器\\n入门\\n字符文本分割器\\nHuggingFace 长度函数\\nLatex 文本分割器\\nMarkdown 文本分割器\\nNLTK 文本分割器\\nPython 代码文本分割器\\n递归字符文本分割器\\nSpacy 文本分割器\\ntiktoken（OpenAI）长度函数\\nTiktoken 文本分割器\\n\\n\\n向量存储\\n入门\\nAtlasDB\\nChroma\\nDeep Lake\\nElasticSearch\\nFAISS\\nMilvus\\nOpenSearch\\nPGVector\\nPinecone\\nQdrant\\nRedis\\nWeaviate\\n\\n\\n检索器\\nChatGPT 插件检索器\\nVectorStore 检索器\\n\\n\\n\\n\\n内存\\n入门\\n操作指南\\nConversationBufferMemory\\nConversationBufferWindowMemory\\n实体内存\\n对话知识图谱内存\\nConversationSummaryMemory\\nConversationSummaryBufferMemory\\nConversationTokenBufferMemory\\n如何将内存添加到 LLMChain\\n如何将内存添加到多输入链\\n如何将内存添加到代理\\n如何自定义对话内存\\n如何创建自定义内存类\\n如何在同一链中使用多个内存类\\n\\n\\n\\n\\n链\\n入门\\n操作指南\\n链的异步 API\\n从 LangChainHub 加载\\nLLM 链\\n顺序链\\n序列化\\n转换链\\n分析文档\\n聊天索引\\n图形 QA\\n假设文档嵌入\\n带来源的问答\\n问答\\n摘要\\n检索问答\\n带来源的检索问答\\n向量数据库文本生成\\nAPI 链\\n带有宪法 AI 的自我批评链\\nBashChain\\nLLMCheckerChain\\nLLM 数学\\nLLMRequestsChain\\nLLMSummarizationCheckerChain\\n审核\\nPAL\\nSQLite 示例\\n\\n\\n参考\\n\\n\\n代理\\n入门\\n工具\\n入门\\n定义自定义工具\\n多输入工具\\nBash\\nBing 搜索\\nChatGPT 插件\\nGoogle 搜索\\nGoogle Serper API\\n人类作为工具\\nIFTTT WebHooks\\nPython REPL\\n请求\\n搜索工具\\nSearxNG 搜索 API\\nSerpAPI\\nWolfram Alpha\\nZapier 自然语言操作 API\\n\\n\\n代理\\n代理类型\\n自定义代理\\n对话代理（用于聊天模型）\\n对话代理\\nMRKL\\nMRKL 聊天\\nReAct\\n自我询问与搜索\\n\\n\\n工具包\\nCSV 代理\\nJSON 代理\\nOpenAPI 代理\\nPandas 数据框代理\\nPython 代理\\nSQL 数据库代理\\n向量存储代理\\n\\n\\n代理执行器\\n如何结合代理和向量存储\\n如何使用代理的异步 API\\n如何创建 ChatGPT 克隆\\n如何访问中间步骤\\n如何限制最大迭代次数\\n如何将共享内存添加到代理及其工具\\n\\n\\n\\n\\n\\n用例\\n\\n个人助理\\n文档问答\\n聊天机器人\\n查询表格数据\\n与 API 交互\\n摘要\\n提取\\n评估\\n代理基准测试：搜索 + 计算器\\n代理 VectorDB 问答基准测试\\n基准测试模板\\n数据增强问答\\n使用 Hugging Face 数据集\\nLLM 数学\\n问答基准测试：保罗·格雷厄姆的文章\\n问答基准测试：国情咨文\\nQA 生成\\n问答\\nSQL 问答基准测试：Chinook\\n\\n\\n\\n参考\\n\\n安装\\n集成\\nAPI 参考\\n提示\\nPromptTemplates\\n示例选择器\\n\\n\\n工具\\nPython REPL\\nSerpAPI\\nSearxNG 搜索\\nDocstore\\n文本分割器\\n嵌入\\n向量存储\\n\\n\\n链\\n代理\\n\\n\\n\\n生态系统\\n\\nLangChain 生态系统\\nAI21 Labs\\nAtlasDB\\nBanana\\nCerebriumAI\\nChroma\\nCohere\\nDeepInfra\\nDeep Lake\\nForefrontAI\\nGoogle 搜索包装器\\nGoogle Serper 包装器\\nGooseAI\\nGraphsignal\\nHazy Research\\nHelicone\\nHugging Face\\nMilvus\\nModal\\nNLPCloud\\nOpenAI\\nOpenSearch\\nPetals\\nPGVector\\nPinecone\\nPromptLayer\\nQdrant\\nRunhouse\\nSearxNG 搜索 API\\nSerpAPI\\nStochasticAI\\nUnstructured\\nWeights & Biases\\nWeaviate\\nWolfram Alpha 包装器\\nWriter\\n\\n\\n\\n附加资源\\n\\nLangChainHub\\n词汇表\\nLangChain 画廊\\n部署\\n追踪\\nDiscord\\n生产支持\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n.rst\\n\\n\\n\\n\\n\\n\\n\\n.pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n欢迎使用 LangChain\\n\\n\\n\\n\\n 目录 \\n\\n\\n\\n入门\\n模块\\n用例\\n参考文档\\nLangChain 生态系统\\n附加资源\\n\\n\\n\\n\\n\\n\\n\\n\\n欢迎使用 LangChain#\\nLangChain 是一个用于开发由语言模型驱动的应用程序的框架。我们相信，最强大和最具差异化的应用程序不仅会通过 API 调用语言模型，还会：\\n\\n具备数据意识：将语言模型连接到其他数据源\\n具备代理性：允许语言模型与其环境交互\\n\\nLangChain 框架是基于上述原则设计的。\\n这是文档的 Python 特定部分。有关 LangChain 的纯概念指南，请参见此处。有关 JavaScript 文档，请参见此处。\\n\\n入门#\\n查看下面的指南，了解如何开始使用 LangChain 创建语言模型应用程序。\\n\\n入门文档\\n\\n\\n\\n\\n\\n模块#\\nLangChain 提供支持的几个主要模块。\\n对于每个模块，我们提供一些示例以供入门、操作指南、参考文档和概念指南。\\n这些模块按复杂程度递增：\\n\\n模型：LangChain 支持的各种模型类型和模型集成。\\n提示：这包括提示管理、提示优化和提示序列化。\\n内存：内存是链/代理调用之间持久化状态的概念。LangChain 提供了内存的标准接口、一系列内存实现，以及使用内存的链/代理示例。\\n索引：当语言模型与您自己的文本数据结合时，通常更强大 - 本模块涵盖了实现这一目标的最佳实践。\\n链：链超越了单一 LLM 调用，是调用的序列（无论是对 LLM 还是其他工具）。LangChain 提供了链的标准接口、与其他工具的众多集成，以及用于常见应用程序的端到端链。\\n代理：代理涉及 LLM 根据要采取的操作做出决策，采取该操作，查看观察结果，并重复该过程，直到完成。LangChain 提供了代理的标准接口、可供选择的代理集合以及端到端代理的示例。\\n\\n\\n\\n\\n\\n用例#\\n上述模块可以以多种方式使用。LangChain 还提供了指导和帮助。以下是 LangChain 支持的一些常见用例。\\n\\n个人助理：主要的 LangChain 用例。个人助理需要采取行动、记住交互并了解您的数据。\\n问答：第二个重要的 LangChain 用例。仅利用这些文档中的信息来回答特定文档上的问题。\\n聊天机器人：由于语言模型擅长生成文本，这使得它们非常适合创建聊天机器人。\\n查询表格数据：如果您想了解如何使用 LLMs 查询存储在表格格式（csv、SQL、数据框等）中的数据，您应该阅读此页面。\\n与 API 交互：使 LLMs 与 API 交互是非常强大的，可以为它们提供更实时的信息并允许它们采取行动。\\n提取：从文本中提取结构化信息。\\n摘要：将较长的文档总结为更短、更精炼的信息块。这也是一种数据增强生成。\\n评估：生成模型通常难以使用传统指标进行评估。评估它们的一种新方法是使用语言模型本身进行评估。LangChain 提供了一些提示/链来协助此过程。\\n\\n\\n\\n\\n\\n参考文档#\\nLangChain 的所有参考文档，集中在一个地方。有关所有方法、类、安装方法和 LangChain 集成设置的完整文档。\\n\\n参考文档\\n\\n\\n\\n\\n\\nLangChain 生态系统#\\n有关其他公司/产品如何与 LangChain 一起使用的指南\\n\\nLangChain 生态系统\\n\\n\\n\\n\\n\\n附加资源#\\n我们认为在您开发应用程序时可能有用的附加资源集合！\\n\\nLangChainHub：LangChainHub 是一个分享和探索其他提示、链和代理的地方。\\n词汇表：所有相关术语、论文、方法等的词汇表。无论是否在 LangChain 中实现！\\n画廊：我们最喜欢的使用 LangChain 的项目集合。对于寻找灵感或查看其他应用程序中的实现方式非常有用。\\n部署：有关部署 LangChain 应用程序的说明、代码片段和模板库的集合。\\n追踪：使用 LangChain 中的追踪可视化链和代理的执行过程的指南。\\n模型实验室：实验不同的提示、模型和链是开发最佳应用程序的重要组成部分。模型实验室使这一过程变得简单。\\nDiscord：加入我们的 Discord，讨论与 LangChain 相关的所有内容！\\n生产支持：当您将 LangChain 转入生产时，我们希望提供更全面的支持。请填写此表格，我们将建立一个专门的支持 Slack 频道。\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n下一个\\n快速入门指南\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n 内容\\n  \\n\\n\\n入门\\n模块\\n用例\\n参考文档\\nLangChain 生态系统\\n附加资源\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n作者：Harrison Chase\\n\\n\\n\\n\\n    \\n      © 版权 2023, Harrison Chase.\\n      \\n\\n\\n\\n\\n  最后更新于 2023年3月27日。\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\', lookup_str=\'\', metadata={\'source\': \'https://python.langchain.com/en/latest/\', \'loc\': \'https://python.langchain.com/en/latest/\', \'lastmod\': \'2023-03-27T22:50:49.790324+00:00\', \'changefreq\': \'daily\', \'priority\': \'0.9\'}, lookup_index=0)添加自定义抓取规则\u200bSitemapLoader 使用 beautifulsoup4 进行抓取过程，默认情况下会抓取页面上的每个元素。SitemapLoader 构造函数接受自定义抓取函数。此功能可以帮助您根据特定需求量身定制抓取过程；例如，您可能希望避免抓取标题或导航元素。以下示例展示了如何开发和使用自定义函数以避免导航和标题元素。导入 beautifulsoup4 库并定义自定义函数.pip install beautifulsoup4from bs4 import BeautifulSoupdef remove_nav_and_header_elements(content: BeautifulSoup) -> str:    # 在 BeautifulSoup 对象中查找所有 'nav' 和 'header' 元素    nav_elements = content.find_all("nav")    header_elements = content.find_all("header")    # 从 BeautifulSoup 对象中删除每个 'nav' 和 'header' 元素    for element in nav_elements + header_elements:        element.decompose()    return str(content.get_text())将自定义函数添加到 SitemapLoader 对象中.loader = SitemapLoader(    "https://langchain.readthedocs.io/sitemap.xml",    filter_urls=["https://python.langchain.com/en/latest/"],    parsing_function=remove_nav_and_header_elements,)本地网站地图\u200b网站地图加载器还可以用于加载本地文件.sitemap_loader = SitemapLoader(web_path="example_data/sitemap.xml", is_local=True)docs = sitemap_loader.load()    Fetching pages: 100%|####################################################################################################################################| 3/3 [00:00<00:00,  3.91it/s]上一个RST下一个Slack过滤网站地图 URLs添加自定义抓取规则本地网站地图社区DiscordTwitterGitHubPythonJS/TS更多主页博客版权 © 2023 LangChain, Inc.\n\n\n\n', metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/sitemap', 'loc': 'https://python.langchain.com/docs/integrations/document_loaders/sitemap', 'changefreq': 'weekly', 'priority': '0.5'})
```



## 添加自定义抓取规则

默认情况下，解析器**移除**所有除文档页面主要内容外的内容，主要内容通常是`<article>`标签。您还可以通过提供一个包含 HTML 标签的列表来定义一个**包含**列表，利用`custom_html_tags`参数。例如：

```python
loader = DocusaurusLoader(
    "https://python.langchain.com",
    filter_urls=[
        "https://python.langchain.com/docs/integrations/document_loaders/sitemap"
    ],
    # 这将仅包括与这些标签匹配的内容，否则它们将被移除
    custom_html_tags=["#content", ".main"],
)
```

如果您需要对每个页面返回的内容进行更细粒度的控制，您还可以定义一个完全自定义的解析函数。

以下示例展示了如何开发和使用自定义函数以避免导航和头部元素。

```python
from bs4 import BeautifulSoup


def remove_nav_and_header_elements(content: BeautifulSoup) -> str:
    # 在 BeautifulSoup 对象中查找所有 'nav' 和 'header' 元素
    nav_elements = content.find_all("nav")
    header_elements = content.find_all("header")

    # 从 BeautifulSoup 对象中移除每个 'nav' 和 'header' 元素
    for element in nav_elements + header_elements:
        element.decompose()

    return str(content.get_text())
```

将您的自定义函数添加到`DocusaurusLoader`对象中。

```python
loader = DocusaurusLoader(
    "https://python.langchain.com",
    filter_urls=[
        "https://python.langchain.com/docs/integrations/document_loaders/sitemap"
    ],
    parsing_function=remove_nav_and_header_elements,
)
```

## 相关

- 文档加载器 [概念指南](/docs/concepts/#document-loaders)
- 文档加载器 [操作指南](/docs/how_to/#document-loaders)