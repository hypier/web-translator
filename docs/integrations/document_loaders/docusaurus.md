---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/integrations/document_loaders/docusaurus.ipynb
---

# Docusaurus
> [Docusaurus](https://docusaurus.io/) æ˜¯ä¸€ä¸ªé™æ€ç½‘ç«™ç”Ÿæˆå™¨ï¼Œæä¾›å¼€ç®±å³ç”¨çš„æ–‡æ¡£åŠŸèƒ½ã€‚

é€šè¿‡åˆ©ç”¨ç°æœ‰çš„ `SitemapLoader`ï¼Œè¯¥åŠ è½½å™¨æ‰«æå¹¶åŠ è½½ç»™å®š Docusaurus åº”ç”¨ä¸­çš„æ‰€æœ‰é¡µé¢ï¼Œå¹¶å°†æ¯ä¸ªé¡µé¢çš„ä¸»è¦æ–‡æ¡£å†…å®¹ä½œä¸ºæ–‡æ¡£è¿”å›ã€‚

```python
from langchain_community.document_loaders import DocusaurusLoader
```

å®‰è£…å¿…è¦çš„ä¾èµ–

```python
%pip install --upgrade --quiet beautifulsoup4 lxml
```

```python
# ä¿®å¤ asyncio å’Œ jupyter çš„ä¸€ä¸ª bug
import nest_asyncio

nest_asyncio.apply()
```

```python
loader = DocusaurusLoader("https://python.langchain.com")

docs = loader.load()
```
```output
Fetching pages: 100%|##########| 939/939 [01:19<00:00, 11.85it/s]
```
> `SitemapLoader` è¿˜æä¾›äº†åˆ©ç”¨å’Œè°ƒæ•´å¹¶å‘æ€§çš„èƒ½åŠ›ï¼Œè¿™å¯ä»¥å¸®åŠ©ä¼˜åŒ–åŠ è½½æºæ–‡æ¡£æ‰€éœ€çš„æ—¶é—´ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [sitemap docs](/docs/integrations/document_loaders/sitemap)ã€‚

```python
docs[0]
```

```output
Document(page_content="\n\n\n\n\nCookbook | ğŸ¦œï¸ğŸ”— Langchain\n\n\n\n\n\n\nSkip to main contentğŸ¦œï¸ğŸ”— LangChainDocsUse casesIntegrationsAPICommunityChat our docsLangSmithJS/TS DocsSearchCTRLKCookbookThe page you're looking for has been moved to the cookbook section of the repo as a notebook.CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.\n\n\n\n", metadata={'source': 'https://python.langchain.com/cookbook', 'loc': 'https://python.langchain.com/cookbook', 'changefreq': 'weekly', 'priority': '0.5'})
```

## è¿‡æ»¤ç½‘ç«™åœ°å›¾ URLs

ç½‘ç«™åœ°å›¾å¯èƒ½åŒ…å«æˆåƒä¸Šä¸‡ä¸ª URLï¼Œé€šå¸¸å¹¶ä¸æ˜¯æ¯ä¸€ä¸ªéƒ½éœ€è¦ã€‚æ‚¨å¯ä»¥é€šè¿‡å°†å­—ç¬¦ä¸²æˆ–æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼çš„åˆ—è¡¨ä¼ é€’ç»™ `url_filter` å‚æ•°æ¥è¿‡æ»¤ URLsã€‚åªæœ‰åŒ¹é…æŸä¸ªæ¨¡å¼çš„ URL æ‰ä¼šè¢«åŠ è½½ã€‚

```python
loader = DocusaurusLoader(
    "https://python.langchain.com",
    filter_urls=[
        "https://python.langchain.com/docs/integrations/document_loaders/sitemap"
    ],
)
documents = loader.load()
```
```output
Fetching pages: 100%|##########| 1/1 [00:00<00:00,  5.21it/s]
```

```python
documents[0]
```

```output
Document(page_content='\n\n\n\n\nSitemap | ğŸ¦œï¸ğŸ”— Langchain\n\n\n\n\n\n\nSkip to main contentğŸ¦œï¸ğŸ”— LangChainDocsUse casesIntegrationsAPICommunityChat our docsLangSmithJS/TS DocsSearchCTRLKProvidersAnthropicAWSGoogleMicrosoftOpenAIMoreComponentsLLMsChat modelsDocument loadersacreomAirbyte CDKAirbyte GongAirbyte HubspotAirbyte JSONAirbyte SalesforceAirbyte ShopifyAirbyte StripeAirbyte TypeformAirbyte Zendesk SupportAirtableAlibaba Cloud MaxComputeApify DatasetArcGISArxivAssemblyAI Audio TranscriptsAsync ChromiumAsyncHtmlAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileAzure Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBrave SearchBrowserlessChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDropboxDuckDBEmailEmbaasEPubEtherscanEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGeopandasGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWiki DumpMerge Documents LoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft SharePointMicrosoft WordModern TreasuryMongoDBNews URLNotion DB 1/2Notion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFrameAmazon TextractPolars DataFramePsychicPubMedPySparkReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS FileTensorFlow Datasets2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas Data FrameYouTube audioYouTube transcriptsDocument transformersText embedding modelsVector storesRetrieversToolsAgents and toolkitsMemoryCallbacksChat loadersComponentsDocument loadersSitemapOn this pageSitemapExtends from the WebBaseLoader, SitemapLoader loads a sitemap from a given URL, and then scrape and load all pages in the sitemap, returning each page as a Document.The scraping is done concurrently.  There are reasonable limits to concurrent requests, defaulting to 2 per second.  If you aren\'t concerned about being a good citizen, or you control the scrapped server, or don\'t care about load. Note, while this will speed up the scraping process, but it may cause the server to block you.  Be careful!pip install nest_asyncio    Requirement already satisfied: nest_asyncio in /Users/tasp/Code/projects/langchain/.venv/lib/python3.10/site-packages (1.5.6)        [notice] A new release of pip available: 22.3.1 -> 23.0.1    [notice] To update, run: pip install --upgrade pip# fixes a bug with asyncio and jupyterimport nest_asyncionest_asyncio.apply()from langchain_community.document_loaders.sitemap import SitemapLoadersitemap_loader = SitemapLoader(web_path="https://langchain.readthedocs.io/sitemap.xml")docs = sitemap_loader.load()You can change the requests_per_second parameter to increase the max concurrent requests. and use requests_kwargs to pass kwargs when send requests.sitemap_loader.requests_per_second = 2# Optional: avoid `[SSL: CERTIFICATE_VERIFY_FAILED]` issuesitemap_loader.requests_kwargs = {"verify": False}docs[0]    Document(page_content=\'\\n\\n\\n\\n\\n\\nWelcome to LangChain â€” ğŸ¦œğŸ”— LangChain 0.0.123\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCtrl+K\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nğŸ¦œğŸ”— LangChain 0.0.123\\n\\n\\n\\nGetting Started\\n\\nQuickstart Guide\\n\\nModules\\n\\nPrompt Templates\\nGetting Started\\nKey Concepts\\nHow-To Guides\\nCreate a custom prompt template\\nCreate a custom example selector\\nProvide few shot examples to a prompt\\nPrompt Serialization\\nExample Selectors\\nOutput Parsers\\n\\n\\nReference\\nPromptTemplates\\nExample Selector\\n\\n\\n\\n\\nLLMs\\nGetting Started\\nKey Concepts\\nHow-To Guides\\nGeneric Functionality\\nCustom LLM\\nFake LLM\\nLLM Caching\\nLLM Serialization\\nToken Usage Tracking\\n\\n\\nIntegrations\\nAI21\\nAleph Alpha\\nAnthropic\\nAzure OpenAI LLM Example\\nBanana\\nCerebriumAI LLM Example\\nCohere\\nDeepInfra LLM Example\\nForefrontAI LLM Example\\nGooseAI LLM Example\\nHugging Face Hub\\nManifest\\nModal\\nOpenAI\\nPetals LLM Example\\nPromptLayer OpenAI\\nSageMakerEndpoint\\nSelf-Hosted Models via Runhouse\\nStochasticAI\\nWriter\\n\\n\\nAsync API for LLM\\nStreaming with LLMs\\n\\n\\nReference\\n\\n\\nDocument Loaders\\nKey Concepts\\nHow To Guides\\nCoNLL-U\\nAirbyte JSON\\nAZLyrics\\nBlackboard\\nCollege Confidential\\nCopy Paste\\nCSV Loader\\nDirectory Loader\\nEmail\\nEverNote\\nFacebook Chat\\nFigma\\nGCS Directory\\nGCS File Storage\\nGitBook\\nGoogle Drive\\nGutenberg\\nHacker News\\nHTML\\niFixit\\nImages\\nIMSDb\\nMarkdown\\nNotebook\\nNotion\\nObsidian\\nPDF\\nPowerPoint\\nReadTheDocs Documentation\\nRoam\\ns3 Directory\\ns3 File\\nSubtitle Files\\nTelegram\\nUnstructured File Loader\\nURL\\nWeb Base\\nWord Documents\\nYouTube\\n\\n\\n\\n\\nUtils\\nKey Concepts\\nGeneric Utilities\\nBash\\nBing Search\\nGoogle Search\\nGoogle Serper API\\nIFTTT WebHooks\\nPython REPL\\nRequests\\nSearxNG Search API\\nSerpAPI\\nWolfram Alpha\\nZapier Natural Language Actions API\\n\\n\\nReference\\nPython REPL\\nSerpAPI\\nSearxNG Search\\nDocstore\\nText Splitter\\nEmbeddings\\nVectorStores\\n\\n\\n\\n\\nIndexes\\nGetting Started\\nKey Concepts\\nHow To Guides\\nEmbeddings\\nHypothetical Document Embeddings\\nText Splitter\\nVectorStores\\nAtlasDB\\nChroma\\nDeep Lake\\nElasticSearch\\nFAISS\\nMilvus\\nOpenSearch\\nPGVector\\nPinecone\\nQdrant\\nRedis\\nWeaviate\\nChatGPT Plugin Retriever\\nVectorStore Retriever\\nAnalyze Document\\nChat Index\\nGraph QA\\nQuestion Answering with Sources\\nQuestion Answering\\nSummarization\\nRetrieval Question/Answering\\nRetrieval Question Answering with Sources\\nVector DB Text Generation\\n\\n\\n\\n\\nChains\\nGetting Started\\nHow-To Guides\\nGeneric Chains\\nLoading from LangChainHub\\nLLM Chain\\nSequential Chains\\nSerialization\\nTransformation Chain\\n\\n\\nUtility Chains\\nAPI Chains\\nSelf-Critique Chain with Constitutional AI\\nBashChain\\nLLMCheckerChain\\nLLM Math\\nLLMRequestsChain\\nLLMSummarizationCheckerChain\\nModeration\\nPAL\\nSQLite example\\n\\n\\nAsync API for Chain\\n\\n\\nKey Concepts\\nReference\\n\\n\\nAgents\\nGetting Started\\nKey Concepts\\nHow-To Guides\\nAgents and Vectorstores\\nAsync API for Agent\\nConversation Agent (for Chat Models)\\nChatGPT Plugins\\nCustom Agent\\nDefining Custom Tools\\nHuman as a tool\\nIntermediate Steps\\nLoading from LangChainHub\\nMax Iterations\\nMulti Input Tools\\nSearch Tools\\nSerialization\\nAdding SharedMemory to an Agent and its Tools\\nCSV Agent\\nJSON Agent\\nOpenAPI Agent\\nPandas Dataframe Agent\\nPython Agent\\nSQL Database Agent\\nVectorstore Agent\\nMRKL\\nMRKL Chat\\nReAct\\nSelf Ask With Search\\n\\n\\nReference\\n\\n\\nMemory\\nGetting Started\\nKey Concepts\\nHow-To Guides\\nConversationBufferMemory\\nConversationBufferWindowMemory\\nEntity Memory\\nConversation Knowledge Graph Memory\\nConversationSummaryMemory\\nConversationSummaryBufferMemory\\nConversationTokenBufferMemory\\nAdding Memory To an LLMChain\\nAdding Memory to a Multi-Input Chain\\nAdding Memory to an Agent\\nChatGPT Clone\\nConversation Agent\\nConversational Memory Customization\\nCustom Memory\\nMultiple Memory\\n\\n\\n\\n\\nChat\\nGetting Started\\nKey Concepts\\nHow-To Guides\\nAgent\\nChat Vector DB\\nFew Shot Examples\\nMemory\\nPromptLayer ChatOpenAI\\nStreaming\\nRetrieval Question/Answering\\nRetrieval Question Answering with Sources\\n\\n\\n\\n\\n\\nUse Cases\\n\\nAgents\\nChatbots\\nGenerate Examples\\nData Augmented Generation\\nQuestion Answering\\nSummarization\\nQuerying Tabular Data\\nExtraction\\nEvaluation\\nAgent Benchmarking: Search + Calculator\\nAgent VectorDB Question Answering Benchmarking\\nBenchmarking Template\\nData Augmented Question Answering\\nUsing Hugging Face Datasets\\nLLM Math\\nQuestion Answering Benchmarking: Paul Graham Essay\\nQuestion Answering Benchmarking: State of the Union Address\\nQA Generation\\nQuestion Answering\\nSQL Question Answering Benchmarking: Chinook\\n\\n\\nModel Comparison\\n\\nReference\\n\\nInstallation\\nIntegrations\\nAPI References\\nPrompts\\nPromptTemplates\\nExample Selector\\n\\n\\nUtilities\\nPython REPL\\nSerpAPI\\nSearxNG Search\\nDocstore\\nText Splitter\\nEmbeddings\\nVectorStores\\n\\n\\nChains\\nAgents\\n\\n\\n\\nEcosystem\\n\\nLangChain Ecosystem\\nAI21 Labs\\nAtlasDB\\nBanana\\nCerebriumAI\\nChroma\\nCohere\\nDeepInfra\\nDeep Lake\\nForefrontAI\\nGoogle Search Wrapper\\nGoogle Serper Wrapper\\nGooseAI\\nGraphsignal\\nHazy Research\\nHelicone\\nHugging Face\\nMilvus\\nModal\\nNLPCloud\\nOpenAI\\nOpenSearch\\nPetals\\nPGVector\\nPinecone\\nPromptLayer\\nQdrant\\nRunhouse\\nSearxNG Search API\\nSerpAPI\\nStochasticAI\\nUnstructured\\nWeights & Biases\\nWeaviate\\nWolfram Alpha Wrapper\\nWriter\\n\\n\\n\\nAdditional Resources\\n\\nLangChainHub\\nGlossary\\nLangChain Gallery\\nDeployments\\nTracing\\nDiscord\\nProduction Support\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n.rst\\n\\n\\n\\n\\n\\n\\n\\n.pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWelcome to LangChain\\n\\n\\n\\n\\n Contents \\n\\n\\n\\nGetting Started\\nModules\\nUse Cases\\nReference Docs\\nLangChain Ecosystem\\nAdditional Resources\\n\\n\\n\\n\\n\\n\\n\\n\\nWelcome to LangChain#\\nå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä½œä¸ºä¸€ç§å˜é©æ€§æŠ€æœ¯æ­£åœ¨å´›èµ·ï¼Œä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿæ„å»ºä»–ä»¬ä¹‹å‰æ— æ³•æ„å»ºçš„åº”ç”¨ç¨‹åºã€‚\\nä½†å•ç‹¬ä½¿ç”¨è¿™äº› LLMs é€šå¸¸ä¸è¶³ä»¥åˆ›å»ºçœŸæ­£å¼ºå¤§çš„åº”ç”¨ç¨‹åº - å…¶çœŸæ­£çš„åŠ›é‡åœ¨äºèƒ½å¤Ÿå°†å®ƒä»¬ä¸å…¶ä»–è®¡ç®—æˆ–çŸ¥è¯†æºç»“åˆèµ·æ¥ã€‚\\nè¯¥åº“æ—¨åœ¨ååŠ©å¼€å‘è¿™äº›ç±»å‹çš„åº”ç”¨ç¨‹åºã€‚è¿™äº›ç±»å‹åº”ç”¨ç¨‹åºçš„å¸¸è§ç¤ºä¾‹åŒ…æ‹¬ï¼š\\nâ“ é’ˆå¯¹ç‰¹å®šæ–‡æ¡£çš„é—®ç­”\\n\\næ–‡æ¡£\\nç«¯åˆ°ç«¯ç¤ºä¾‹ï¼šé’ˆå¯¹ Notion æ•°æ®åº“çš„é—®ç­”\\n\\nğŸ’¬ èŠå¤©æœºå™¨äºº\\n\\næ–‡æ¡£\\nç«¯åˆ°ç«¯ç¤ºä¾‹ï¼šChat-LangChain\\n\\nğŸ¤– ä»£ç†\\n\\næ–‡æ¡£\\nç«¯åˆ°ç«¯ç¤ºä¾‹ï¼šGPT+WolframAlpha\\n\\n\\nå…¥é—¨#\\næŸ¥çœ‹ä¸‹é¢çš„æŒ‡å—ï¼Œäº†è§£å¦‚ä½•å¼€å§‹ä½¿ç”¨ LangChain åˆ›å»ºè¯­è¨€æ¨¡å‹åº”ç”¨ç¨‹åºã€‚\\n\\nå…¥é—¨æ–‡æ¡£\\n\\n\\n\\n\\n\\næ¨¡å—#\\nLangChain æä¾›æ”¯æŒçš„å‡ ä¸ªä¸»è¦æ¨¡å—ã€‚\\nå¯¹äºæ¯ä¸ªæ¨¡å—ï¼Œæˆ‘ä»¬æä¾›ä¸€äº›ç¤ºä¾‹ä»¥ä¾›å…¥é—¨ã€æ“ä½œæŒ‡å—ã€å‚è€ƒæ–‡æ¡£å’Œæ¦‚å¿µæŒ‡å—ã€‚\\nè¿™äº›æ¨¡å—æŒ‰å¤æ‚ç¨‹åº¦é€’å¢ï¼š\\n\\næç¤ºï¼šè¿™åŒ…æ‹¬æç¤ºç®¡ç†ã€æç¤ºä¼˜åŒ–å’Œæç¤ºåºåˆ—åŒ–ã€‚\\nLLMsï¼šè¿™åŒ…æ‹¬æ‰€æœ‰ LLMs çš„é€šç”¨æ¥å£ï¼Œä»¥åŠå¤„ç† LLMs çš„å¸¸ç”¨å·¥å…·ã€‚\\næ–‡æ¡£åŠ è½½å™¨ï¼šè¿™åŒ…æ‹¬åŠ è½½æ–‡æ¡£çš„æ ‡å‡†æ¥å£ï¼Œä»¥åŠä¸æ‰€æœ‰ç±»å‹æ–‡æœ¬æ•°æ®æºçš„ç‰¹å®šé›†æˆã€‚\\nå·¥å…·ï¼šå½“è¯­è¨€æ¨¡å‹ä¸å…¶ä»–çŸ¥è¯†æˆ–è®¡ç®—æºäº¤äº’æ—¶ï¼Œé€šå¸¸æ›´å¼ºå¤§ã€‚è¿™å¯ä»¥åŒ…æ‹¬ Python REPLã€åµŒå…¥ã€æœç´¢å¼•æ“ç­‰ã€‚LangChain æä¾›äº†å¤§é‡å¸¸ç”¨å·¥å…·ï¼Œä¾›æ‚¨åœ¨åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨ã€‚\\né“¾ï¼šé“¾è¶…è¶Šäº†å•ä¸€ LLM è°ƒç”¨ï¼Œæ˜¯è°ƒç”¨çš„åºåˆ—ï¼ˆæ— è®ºæ˜¯å¯¹ LLM è¿˜æ˜¯å…¶ä»–å·¥å…·ï¼‰ã€‚LangChain æä¾›äº†é“¾çš„æ ‡å‡†æ¥å£ã€ä¸å…¶ä»–å·¥å…·çš„ä¼—å¤šé›†æˆï¼Œä»¥åŠç”¨äºå¸¸è§åº”ç”¨ç¨‹åºçš„ç«¯åˆ°ç«¯é“¾ã€‚\\nç´¢å¼•ï¼šå½“è¯­è¨€æ¨¡å‹ä¸æ‚¨è‡ªå·±çš„æ–‡æœ¬æ•°æ®ç»“åˆæ—¶ï¼Œé€šå¸¸æ›´å¼ºå¤§ - æœ¬æ¨¡å—æ¶µç›–äº†å®ç°è¿™ä¸€ç›®æ ‡çš„æœ€ä½³å®è·µã€‚\\nä»£ç†ï¼šä»£ç†æ¶‰åŠ LLM æ ¹æ®è¦é‡‡å–çš„æ“ä½œåšå‡ºå†³ç­–ï¼Œé‡‡å–è¯¥æ“ä½œï¼ŒæŸ¥çœ‹è§‚å¯Ÿç»“æœï¼Œå¹¶é‡å¤è¯¥è¿‡ç¨‹ï¼Œç›´åˆ°å®Œæˆã€‚LangChain æä¾›äº†ä»£ç†çš„æ ‡å‡†æ¥å£ã€å¯ä¾›é€‰æ‹©çš„ä»£ç†é›†åˆä»¥åŠç«¯åˆ°ç«¯ä»£ç†çš„ç¤ºä¾‹ã€‚\\n\\n\\n\\n\\n\\nç”¨ä¾‹#\\nä¸Šè¿°æ¨¡å—å¯ä»¥ä»¥å¤šç§æ–¹å¼ä½¿ç”¨ã€‚LangChain è¿˜æä¾›äº†æŒ‡å¯¼å’Œå¸®åŠ©ã€‚ä»¥ä¸‹æ˜¯ LangChain æ”¯æŒçš„ä¸€äº›å¸¸è§ç”¨ä¾‹ã€‚\\n\\nä»£ç†ï¼šä»£ç†æ˜¯ä½¿ç”¨è¯­è¨€æ¨¡å‹ä¸å…¶ä»–å·¥å…·äº¤äº’çš„ç³»ç»Ÿã€‚è¿™äº›å¯ä»¥ç”¨äºæ›´æ‰å®çš„é—®ç­”ã€ä¸ API äº¤äº’ï¼Œç”šè‡³é‡‡å–è¡ŒåŠ¨ã€‚\\nèŠå¤©æœºå™¨äººï¼šç”±äºè¯­è¨€æ¨¡å‹æ“…é•¿ç”Ÿæˆæ–‡æœ¬ï¼Œè¿™ä½¿å¾—å®ƒä»¬éå¸¸é€‚åˆåˆ›å»ºèŠå¤©æœºå™¨äººã€‚\\næ•°æ®å¢å¼ºç”Ÿæˆï¼šæ•°æ®å¢å¼ºç”Ÿæˆæ¶‰åŠç‰¹å®šç±»å‹çš„é“¾ï¼Œé¦–å…ˆä¸å¤–éƒ¨æ•°æ®æºäº¤äº’ï¼Œä»¥è·å–ç”¨äºç”Ÿæˆæ­¥éª¤çš„æ•°æ®ã€‚è¿™åŒ…æ‹¬é•¿æ–‡æœ¬çš„æ‘˜è¦å’Œé’ˆå¯¹ç‰¹å®šæ•°æ®æºçš„é—®ç­”ã€‚\\né—®ç­”ï¼šä»…åˆ©ç”¨è¿™äº›æ–‡æ¡£ä¸­çš„ä¿¡æ¯æ¥å›ç­”ç‰¹å®šæ–‡æ¡£ä¸Šçš„é—®é¢˜ã€‚è¿™æ˜¯ä¸€ç§æ•°æ®å¢å¼ºç”Ÿæˆã€‚\\næ‘˜è¦ï¼šå°†è¾ƒé•¿çš„æ–‡æ¡£æ€»ç»“ä¸ºæ›´çŸ­ã€æ›´ç²¾ç‚¼çš„ä¿¡æ¯å—ã€‚è¿™ä¹Ÿæ˜¯ä¸€ç§æ•°æ®å¢å¼ºç”Ÿæˆã€‚\\næŸ¥è¯¢è¡¨æ ¼æ•°æ®ï¼šå¦‚æœæ‚¨æƒ³äº†è§£å¦‚ä½•ä½¿ç”¨ LLMs æŸ¥è¯¢å­˜å‚¨åœ¨è¡¨æ ¼æ ¼å¼ï¼ˆcsvã€SQLã€æ•°æ®æ¡†ç­‰ï¼‰ä¸­çš„æ•°æ®ï¼Œæ‚¨åº”è¯¥é˜…è¯»æ­¤é¡µé¢ã€‚\\nè¯„ä¼°ï¼šç”Ÿæˆæ¨¡å‹é€šå¸¸éš¾ä»¥ä½¿ç”¨ä¼ ç»ŸæŒ‡æ ‡è¿›è¡Œè¯„ä¼°ã€‚è¯„ä¼°å®ƒä»¬çš„ä¸€ç§æ–°æ–¹æ³•æ˜¯ä½¿ç”¨è¯­è¨€æ¨¡å‹æœ¬èº«è¿›è¡Œè¯„ä¼°ã€‚LangChain æä¾›äº†ä¸€äº›æç¤º/é“¾æ¥ååŠ©æ­¤è¿‡ç¨‹ã€‚\\nç”Ÿæˆç±»ä¼¼ç¤ºä¾‹ï¼šç”Ÿæˆä¸ç»™å®šè¾“å…¥ç›¸ä¼¼çš„ç¤ºä¾‹ã€‚è¿™æ˜¯è®¸å¤šåº”ç”¨ç¨‹åºçš„å¸¸è§ç”¨ä¾‹ï¼ŒLangChain æä¾›äº†ä¸€äº›æç¤º/é“¾æ¥ååŠ©æ­¤è¿‡ç¨‹ã€‚\\næ¯”è¾ƒæ¨¡å‹ï¼šå®éªŒä¸åŒçš„æç¤ºã€æ¨¡å‹å’Œé“¾æ˜¯å¼€å‘æœ€ä½³åº”ç”¨ç¨‹åºçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚æ¨¡å‹å®éªŒå®¤ä½¿è¿™ä¸€è¿‡ç¨‹å˜å¾—ç®€å•ã€‚\\n\\n\\n\\n\\n\\nå‚è€ƒæ–‡æ¡£#\\nLangChain çš„æ‰€æœ‰å‚è€ƒæ–‡æ¡£ï¼Œé›†ä¸­åœ¨ä¸€ä¸ªåœ°æ–¹ã€‚æœ‰å…³æ‰€æœ‰æ–¹æ³•ã€ç±»ã€å®‰è£…æ–¹æ³•å’Œ LangChain é›†æˆè®¾ç½®çš„å®Œæ•´æ–‡æ¡£ã€‚\\n\\nå‚è€ƒæ–‡æ¡£\\n\\n\\n\\n\\n\\nLangChain ç”Ÿæ€ç³»ç»Ÿ#\\næœ‰å…³å…¶ä»–å…¬å¸/äº§å“å¦‚ä½•ä¸ LangChain ä¸€èµ·ä½¿ç”¨çš„æŒ‡å—\\n\\nLangChain ç”Ÿæ€ç³»ç»Ÿ\\n\\n\\n\\n\\n\\né™„åŠ èµ„æº#\\næˆ‘ä»¬è®¤ä¸ºåœ¨æ‚¨å¼€å‘åº”ç”¨ç¨‹åºæ—¶å¯èƒ½æœ‰ç”¨çš„é™„åŠ èµ„æºé›†åˆï¼\\n\\nLangChainHubï¼šLangChainHub æ˜¯ä¸€ä¸ªåˆ†äº«å’Œæ¢ç´¢å…¶ä»–æç¤ºã€é“¾å’Œä»£ç†çš„åœ°æ–¹ã€‚\\nè¯æ±‡è¡¨ï¼šæ‰€æœ‰ç›¸å…³æœ¯è¯­ã€è®ºæ–‡ã€æ–¹æ³•ç­‰çš„è¯æ±‡è¡¨ã€‚æ— è®ºæ˜¯å¦åœ¨ LangChain ä¸­å®ç°ï¼\\nç”»å»Šï¼šæˆ‘ä»¬æœ€å–œæ¬¢çš„ä½¿ç”¨ LangChain çš„é¡¹ç›®é›†åˆã€‚å¯¹äºå¯»æ‰¾çµæ„Ÿæˆ–æŸ¥çœ‹å…¶ä»–åº”ç”¨ç¨‹åºä¸­çš„å®ç°æ–¹å¼éå¸¸æœ‰ç”¨ã€‚\\néƒ¨ç½²ï¼šæœ‰å…³éƒ¨ç½² LangChain åº”ç”¨ç¨‹åºçš„è¯´æ˜ã€ä»£ç ç‰‡æ®µå’Œæ¨¡æ¿åº“çš„é›†åˆã€‚\\nDiscordï¼šåŠ å…¥æˆ‘ä»¬çš„ Discordï¼Œè®¨è®ºä¸ LangChain ç›¸å…³çš„æ‰€æœ‰å†…å®¹ï¼\\nè¿½è¸ªï¼šä½¿ç”¨ LangChain ä¸­çš„è¿½è¸ªå¯è§†åŒ–é“¾å’Œä»£ç†çš„æ‰§è¡Œè¿‡ç¨‹çš„æŒ‡å—ã€‚\\nç”Ÿäº§æ”¯æŒï¼šå½“æ‚¨å°† LangChain è½¬å…¥ç”Ÿäº§æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›æä¾›æ›´å…¨é¢çš„æ”¯æŒã€‚è¯·å¡«å†™æ­¤è¡¨æ ¼ï¼Œæˆ‘ä»¬å°†å»ºç«‹ä¸€ä¸ªä¸“é—¨çš„æ”¯æŒ Slack é¢‘é“ã€‚\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nä¸‹ä¸€ä¸ª\\nå¿«é€Ÿå…¥é—¨æŒ‡å—\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n å†…å®¹\\n  \\n\\n\\nå…¥é—¨\\næ¨¡å—\\nç”¨ä¾‹\\nå‚è€ƒæ–‡æ¡£\\nLangChain ç”Ÿæ€ç³»ç»Ÿ\\né™„åŠ èµ„æº\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nä½œè€…ï¼šHarrison Chase\\n\\n\\n\\n\\n    \\n      Â© ç‰ˆæƒ 2023, Harrison Chase.\\n      \\n\\n\\n\\n\\n  æœ€åæ›´æ–°äº 2023å¹´3æœˆ24æ—¥ã€‚\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\', lookup_str=\'\', metadata={\'source\': \'https://python.langchain.com/en/stable/\', \'loc\': \'https://python.langchain.com/en/stable/\', \'lastmod\': \'2023-03-24T19:30:54.647430+00:00\', \'changefreq\': \'weekly\', \'priority\': \'1\'}, lookup_index=0)è¿‡æ»¤ç½‘ç«™åœ°å›¾ URLs\u200bç½‘ç«™åœ°å›¾å¯èƒ½æ˜¯å¤§å‹æ–‡ä»¶ï¼ŒåŒ…å«æˆåƒä¸Šä¸‡ä¸ª URLã€‚é€šå¸¸æ‚¨å¹¶ä¸éœ€è¦æ¯ä¸€ä¸ª URLã€‚æ‚¨å¯ä»¥é€šè¿‡å°†å­—ç¬¦ä¸²æˆ–æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼çš„åˆ—è¡¨ä¼ é€’ç»™ url_filter å‚æ•°æ¥è¿‡æ»¤ URLsã€‚åªæœ‰åŒ¹é…æŸä¸ªæ¨¡å¼çš„ URL æ‰ä¼šè¢«åŠ è½½.loader = SitemapLoader(    "https://langchain.readthedocs.io/sitemap.xml",    filter_urls=["https://python.langchain.com/en/latest/"],)documents = loader.load()documents[0]    Document(page_content=\'\\n\\n\\n\\n\\n\\næ¬¢è¿ä½¿ç”¨ LangChain â€” ğŸ¦œğŸ”— LangChain 0.0.123\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nè·³è½¬åˆ°ä¸»è¦å†…å®¹\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCtrl+K\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nğŸ¦œğŸ”— LangChain 0.0.123\\n\\n\\n\\nå…¥é—¨\\n\\nå¿«é€Ÿå…¥é—¨æŒ‡å—\\n\\næ¨¡å—\\n\\næ¨¡å‹\\nLLMs\\nå…¥é—¨\\né€šç”¨åŠŸèƒ½\\nå¦‚ä½•ä½¿ç”¨ LLM çš„å¼‚æ­¥ API\\nå¦‚ä½•ç¼–å†™è‡ªå®šä¹‰ LLM åŒ…è£…å™¨\\nå¦‚ä½•ï¼ˆä»¥åŠä¸ºä»€ä¹ˆï¼‰ä½¿ç”¨å‡ LLM\\nå¦‚ä½•ç¼“å­˜ LLM è°ƒç”¨\\nå¦‚ä½•åºåˆ—åŒ– LLM ç±»\\nå¦‚ä½•æµå¼ä¼ è¾“ LLM å“åº”\\nå¦‚ä½•è·Ÿè¸ªä»¤ç‰Œä½¿ç”¨\\n\\n\\né›†æˆ\\nAI21\\nAleph Alpha\\nAnthropic\\nAzure OpenAI LLM ç¤ºä¾‹\\nBanana\\nCerebriumAI LLM ç¤ºä¾‹\\nCohere\\nDeepInfra LLM ç¤ºä¾‹\\nForefrontAI LLM ç¤ºä¾‹\\nGooseAI LLM ç¤ºä¾‹\\nHugging Face Hub\\nManifest\\nModal\\nOpenAI\\nPetals LLM ç¤ºä¾‹\\nPromptLayer OpenAI\\nSageMakerEndpoint\\né€šè¿‡ Runhouse è‡ªæ‰˜ç®¡æ¨¡å‹\\nStochasticAI\\nWriter\\n\\n\\nå‚è€ƒ\\n\\n\\nèŠå¤©æ¨¡å‹\\nå…¥é—¨\\næ“ä½œæŒ‡å—\\nå¦‚ä½•ä½¿ç”¨å°‘é‡ç¤ºä¾‹\\nå¦‚ä½•æµå¼ä¼ è¾“å“åº”\\n\\n\\né›†æˆ\\nAzure\\nOpenAI\\nPromptLayer ChatOpenAI\\n\\n\\n\\n\\næ–‡æœ¬åµŒå…¥æ¨¡å‹\\nAzureOpenAI\\nCohere\\nå‡åµŒå…¥\\nHugging Face Hub\\nInstructEmbeddings\\nOpenAI\\nSageMaker Endpoint åµŒå…¥\\nè‡ªæ‰˜ç®¡åµŒå…¥\\nTensorflowHub\\n\\n\\n\\n\\næç¤º\\næç¤ºæ¨¡æ¿\\nå…¥é—¨\\næ“ä½œæŒ‡å—\\nå¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰æç¤ºæ¨¡æ¿\\nå¦‚ä½•åˆ›å»ºä½¿ç”¨å°‘é‡ç¤ºä¾‹çš„æç¤ºæ¨¡æ¿\\nå¦‚ä½•å¤„ç†éƒ¨åˆ†æç¤ºæ¨¡æ¿\\nå¦‚ä½•åºåˆ—åŒ–æç¤º\\n\\n\\nå‚è€ƒ\\nPromptTemplates\\nç¤ºä¾‹é€‰æ‹©å™¨\\n\\n\\n\\n\\nèŠå¤©æç¤ºæ¨¡æ¿\\nç¤ºä¾‹é€‰æ‹©å™¨\\nå¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰ç¤ºä¾‹é€‰æ‹©å™¨\\nåŸºäºé•¿åº¦çš„ç¤ºä¾‹é€‰æ‹©å™¨\\næœ€å¤§è¾¹é™…ç›¸å…³æ€§ç¤ºä¾‹é€‰æ‹©å™¨\\nNGram é‡å ç¤ºä¾‹é€‰æ‹©å™¨\\nç›¸ä¼¼æ€§ç¤ºä¾‹é€‰æ‹©å™¨\\n\\n\\nè¾“å‡ºè§£æå™¨\\nè¾“å‡ºè§£æå™¨\\né€—å·åˆ†éš”åˆ—è¡¨è¾“å‡ºè§£æå™¨\\nè¾“å‡ºä¿®å¤è§£æå™¨\\nPydantic è¾“å‡ºè§£æå™¨\\né‡è¯•è¾“å‡ºè§£æå™¨\\nç»“æ„åŒ–è¾“å‡ºè§£æå™¨\\n\\n\\n\\n\\nç´¢å¼•\\nå…¥é—¨\\næ–‡æ¡£åŠ è½½å™¨\\nCoNLL-U\\nAirbyte JSON\\nAZLyrics\\nBlackboard\\nCollege Confidential\\nå¤åˆ¶ç²˜è´´\\nCSV åŠ è½½å™¨\\nç›®å½•åŠ è½½å™¨\\nç”µå­é‚®ä»¶\\nEverNote\\nFacebook èŠå¤©\\nFigma\\nGCS ç›®å½•\\nGCS æ–‡ä»¶å­˜å‚¨\\nGitBook\\nGoogle Drive\\nGutenberg\\nHacker News\\nHTML\\niFixit\\nå›¾åƒ\\nIMSDb\\nMarkdown\\nç¬”è®°æœ¬\\nNotion\\nObsidian\\nPDF\\nPowerPoint\\nReadTheDocs æ–‡æ¡£\\nRoam\\ns3 ç›®å½•\\ns3 æ–‡ä»¶\\nå­—å¹•æ–‡ä»¶\\nTelegram\\néç»“æ„åŒ–æ–‡ä»¶åŠ è½½å™¨\\nURL\\nWeb Base\\nWord æ–‡æ¡£\\nYouTube\\n\\n\\næ–‡æœ¬åˆ†å‰²å™¨\\nå…¥é—¨\\nå­—ç¬¦æ–‡æœ¬åˆ†å‰²å™¨\\nHuggingFace é•¿åº¦å‡½æ•°\\nLatex æ–‡æœ¬åˆ†å‰²å™¨\\nMarkdown æ–‡æœ¬åˆ†å‰²å™¨\\nNLTK æ–‡æœ¬åˆ†å‰²å™¨\\nPython ä»£ç æ–‡æœ¬åˆ†å‰²å™¨\\né€’å½’å­—ç¬¦æ–‡æœ¬åˆ†å‰²å™¨\\nSpacy æ–‡æœ¬åˆ†å‰²å™¨\\ntiktokenï¼ˆOpenAIï¼‰é•¿åº¦å‡½æ•°\\nTiktoken æ–‡æœ¬åˆ†å‰²å™¨\\n\\n\\nå‘é‡å­˜å‚¨\\nå…¥é—¨\\nAtlasDB\\nChroma\\nDeep Lake\\nElasticSearch\\nFAISS\\nMilvus\\nOpenSearch\\nPGVector\\nPinecone\\nQdrant\\nRedis\\nWeaviate\\n\\n\\næ£€ç´¢å™¨\\nChatGPT æ’ä»¶æ£€ç´¢å™¨\\nVectorStore æ£€ç´¢å™¨\\n\\n\\n\\n\\nå†…å­˜\\nå…¥é—¨\\næ“ä½œæŒ‡å—\\nConversationBufferMemory\\nConversationBufferWindowMemory\\nå®ä½“å†…å­˜\\nå¯¹è¯çŸ¥è¯†å›¾è°±å†…å­˜\\nConversationSummaryMemory\\nConversationSummaryBufferMemory\\nConversationTokenBufferMemory\\nå¦‚ä½•å°†å†…å­˜æ·»åŠ åˆ° LLMChain\\nå¦‚ä½•å°†å†…å­˜æ·»åŠ åˆ°å¤šè¾“å…¥é“¾\\nå¦‚ä½•å°†å†…å­˜æ·»åŠ åˆ°ä»£ç†\\nå¦‚ä½•è‡ªå®šä¹‰å¯¹è¯å†…å­˜\\nå¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰å†…å­˜ç±»\\nå¦‚ä½•åœ¨åŒä¸€é“¾ä¸­ä½¿ç”¨å¤šä¸ªå†…å­˜ç±»\\n\\n\\n\\n\\né“¾\\nå…¥é—¨\\næ“ä½œæŒ‡å—\\né“¾çš„å¼‚æ­¥ API\\nä» LangChainHub åŠ è½½\\nLLM é“¾\\né¡ºåºé“¾\\nåºåˆ—åŒ–\\nè½¬æ¢é“¾\\nåˆ†ææ–‡æ¡£\\nèŠå¤©ç´¢å¼•\\nå›¾å½¢ QA\\nå‡è®¾æ–‡æ¡£åµŒå…¥\\nå¸¦æ¥æºçš„é—®ç­”\\né—®ç­”\\næ‘˜è¦\\næ£€ç´¢é—®ç­”\\nå¸¦æ¥æºçš„æ£€ç´¢é—®ç­”\\nå‘é‡æ•°æ®åº“æ–‡æœ¬ç”Ÿæˆ\\nAPI é“¾\\nå¸¦æœ‰å®ªæ³• AI çš„è‡ªæˆ‘æ‰¹è¯„é“¾\\nBashChain\\nLLMCheckerChain\\nLLM æ•°å­¦\\nLLMRequestsChain\\nLLMSummarizationCheckerChain\\nå®¡æ ¸\\nPAL\\nSQLite ç¤ºä¾‹\\n\\n\\nå‚è€ƒ\\n\\n\\nä»£ç†\\nå…¥é—¨\\nå·¥å…·\\nå…¥é—¨\\nå®šä¹‰è‡ªå®šä¹‰å·¥å…·\\nå¤šè¾“å…¥å·¥å…·\\nBash\\nBing æœç´¢\\nChatGPT æ’ä»¶\\nGoogle æœç´¢\\nGoogle Serper API\\näººç±»ä½œä¸ºå·¥å…·\\nIFTTT WebHooks\\nPython REPL\\nè¯·æ±‚\\næœç´¢å·¥å…·\\nSearxNG æœç´¢ API\\nSerpAPI\\nWolfram Alpha\\nZapier è‡ªç„¶è¯­è¨€æ“ä½œ API\\n\\n\\nä»£ç†\\nä»£ç†ç±»å‹\\nè‡ªå®šä¹‰ä»£ç†\\nå¯¹è¯ä»£ç†ï¼ˆç”¨äºèŠå¤©æ¨¡å‹ï¼‰\\nå¯¹è¯ä»£ç†\\nMRKL\\nMRKL èŠå¤©\\nReAct\\nè‡ªæˆ‘è¯¢é—®ä¸æœç´¢\\n\\n\\nå·¥å…·åŒ…\\nCSV ä»£ç†\\nJSON ä»£ç†\\nOpenAPI ä»£ç†\\nPandas æ•°æ®æ¡†ä»£ç†\\nPython ä»£ç†\\nSQL æ•°æ®åº“ä»£ç†\\nå‘é‡å­˜å‚¨ä»£ç†\\n\\n\\nä»£ç†æ‰§è¡Œå™¨\\nå¦‚ä½•ç»“åˆä»£ç†å’Œå‘é‡å­˜å‚¨\\nå¦‚ä½•ä½¿ç”¨ä»£ç†çš„å¼‚æ­¥ API\\nå¦‚ä½•åˆ›å»º ChatGPT å…‹éš†\\nå¦‚ä½•è®¿é—®ä¸­é—´æ­¥éª¤\\nå¦‚ä½•é™åˆ¶æœ€å¤§è¿­ä»£æ¬¡æ•°\\nå¦‚ä½•å°†å…±äº«å†…å­˜æ·»åŠ åˆ°ä»£ç†åŠå…¶å·¥å…·\\n\\n\\n\\n\\n\\nç”¨ä¾‹\\n\\nä¸ªäººåŠ©ç†\\næ–‡æ¡£é—®ç­”\\nèŠå¤©æœºå™¨äºº\\næŸ¥è¯¢è¡¨æ ¼æ•°æ®\\nä¸ API äº¤äº’\\næ‘˜è¦\\næå–\\nè¯„ä¼°\\nä»£ç†åŸºå‡†æµ‹è¯•ï¼šæœç´¢ + è®¡ç®—å™¨\\nä»£ç† VectorDB é—®ç­”åŸºå‡†æµ‹è¯•\\nåŸºå‡†æµ‹è¯•æ¨¡æ¿\\næ•°æ®å¢å¼ºé—®ç­”\\nä½¿ç”¨ Hugging Face æ•°æ®é›†\\nLLM æ•°å­¦\\né—®ç­”åŸºå‡†æµ‹è¯•ï¼šä¿ç½—Â·æ ¼é›·å„å§†çš„æ–‡ç« \\né—®ç­”åŸºå‡†æµ‹è¯•ï¼šå›½æƒ…å’¨æ–‡\\nQA ç”Ÿæˆ\\né—®ç­”\\nSQL é—®ç­”åŸºå‡†æµ‹è¯•ï¼šChinook\\n\\n\\n\\nå‚è€ƒ\\n\\nå®‰è£…\\né›†æˆ\\nAPI å‚è€ƒ\\næç¤º\\nPromptTemplates\\nç¤ºä¾‹é€‰æ‹©å™¨\\n\\n\\nå·¥å…·\\nPython REPL\\nSerpAPI\\nSearxNG æœç´¢\\nDocstore\\næ–‡æœ¬åˆ†å‰²å™¨\\nåµŒå…¥\\nå‘é‡å­˜å‚¨\\n\\n\\né“¾\\nä»£ç†\\n\\n\\n\\nç”Ÿæ€ç³»ç»Ÿ\\n\\nLangChain ç”Ÿæ€ç³»ç»Ÿ\\nAI21 Labs\\nAtlasDB\\nBanana\\nCerebriumAI\\nChroma\\nCohere\\nDeepInfra\\nDeep Lake\\nForefrontAI\\nGoogle æœç´¢åŒ…è£…å™¨\\nGoogle Serper åŒ…è£…å™¨\\nGooseAI\\nGraphsignal\\nHazy Research\\nHelicone\\nHugging Face\\nMilvus\\nModal\\nNLPCloud\\nOpenAI\\nOpenSearch\\nPetals\\nPGVector\\nPinecone\\nPromptLayer\\nQdrant\\nRunhouse\\nSearxNG æœç´¢ API\\nSerpAPI\\nStochasticAI\\nUnstructured\\nWeights & Biases\\nWeaviate\\nWolfram Alpha åŒ…è£…å™¨\\nWriter\\n\\n\\n\\né™„åŠ èµ„æº\\n\\nLangChainHub\\nè¯æ±‡è¡¨\\nLangChain ç”»å»Š\\néƒ¨ç½²\\nè¿½è¸ª\\nDiscord\\nç”Ÿäº§æ”¯æŒ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n.rst\\n\\n\\n\\n\\n\\n\\n\\n.pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\næ¬¢è¿ä½¿ç”¨ LangChain\\n\\n\\n\\n\\n ç›®å½• \\n\\n\\n\\nå…¥é—¨\\næ¨¡å—\\nç”¨ä¾‹\\nå‚è€ƒæ–‡æ¡£\\nLangChain ç”Ÿæ€ç³»ç»Ÿ\\né™„åŠ èµ„æº\\n\\n\\n\\n\\n\\n\\n\\n\\næ¬¢è¿ä½¿ç”¨ LangChain#\\nLangChain æ˜¯ä¸€ä¸ªç”¨äºå¼€å‘ç”±è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œæœ€å¼ºå¤§å’Œæœ€å…·å·®å¼‚åŒ–çš„åº”ç”¨ç¨‹åºä¸ä»…ä¼šé€šè¿‡ API è°ƒç”¨è¯­è¨€æ¨¡å‹ï¼Œè¿˜ä¼šï¼š\\n\\nå…·å¤‡æ•°æ®æ„è¯†ï¼šå°†è¯­è¨€æ¨¡å‹è¿æ¥åˆ°å…¶ä»–æ•°æ®æº\\nå…·å¤‡ä»£ç†æ€§ï¼šå…è®¸è¯­è¨€æ¨¡å‹ä¸å…¶ç¯å¢ƒäº¤äº’\\n\\nLangChain æ¡†æ¶æ˜¯åŸºäºä¸Šè¿°åŸåˆ™è®¾è®¡çš„ã€‚\\nè¿™æ˜¯æ–‡æ¡£çš„ Python ç‰¹å®šéƒ¨åˆ†ã€‚æœ‰å…³ LangChain çš„çº¯æ¦‚å¿µæŒ‡å—ï¼Œè¯·å‚è§æ­¤å¤„ã€‚æœ‰å…³ JavaScript æ–‡æ¡£ï¼Œè¯·å‚è§æ­¤å¤„ã€‚\\n\\nå…¥é—¨#\\næŸ¥çœ‹ä¸‹é¢çš„æŒ‡å—ï¼Œäº†è§£å¦‚ä½•å¼€å§‹ä½¿ç”¨ LangChain åˆ›å»ºè¯­è¨€æ¨¡å‹åº”ç”¨ç¨‹åºã€‚\\n\\nå…¥é—¨æ–‡æ¡£\\n\\n\\n\\n\\n\\næ¨¡å—#\\nLangChain æä¾›æ”¯æŒçš„å‡ ä¸ªä¸»è¦æ¨¡å—ã€‚\\nå¯¹äºæ¯ä¸ªæ¨¡å—ï¼Œæˆ‘ä»¬æä¾›ä¸€äº›ç¤ºä¾‹ä»¥ä¾›å…¥é—¨ã€æ“ä½œæŒ‡å—ã€å‚è€ƒæ–‡æ¡£å’Œæ¦‚å¿µæŒ‡å—ã€‚\\nè¿™äº›æ¨¡å—æŒ‰å¤æ‚ç¨‹åº¦é€’å¢ï¼š\\n\\næ¨¡å‹ï¼šLangChain æ”¯æŒçš„å„ç§æ¨¡å‹ç±»å‹å’Œæ¨¡å‹é›†æˆã€‚\\næç¤ºï¼šè¿™åŒ…æ‹¬æç¤ºç®¡ç†ã€æç¤ºä¼˜åŒ–å’Œæç¤ºåºåˆ—åŒ–ã€‚\\nå†…å­˜ï¼šå†…å­˜æ˜¯é“¾/ä»£ç†è°ƒç”¨ä¹‹é—´æŒä¹…åŒ–çŠ¶æ€çš„æ¦‚å¿µã€‚LangChain æä¾›äº†å†…å­˜çš„æ ‡å‡†æ¥å£ã€ä¸€ç³»åˆ—å†…å­˜å®ç°ï¼Œä»¥åŠä½¿ç”¨å†…å­˜çš„é“¾/ä»£ç†ç¤ºä¾‹ã€‚\\nç´¢å¼•ï¼šå½“è¯­è¨€æ¨¡å‹ä¸æ‚¨è‡ªå·±çš„æ–‡æœ¬æ•°æ®ç»“åˆæ—¶ï¼Œé€šå¸¸æ›´å¼ºå¤§ - æœ¬æ¨¡å—æ¶µç›–äº†å®ç°è¿™ä¸€ç›®æ ‡çš„æœ€ä½³å®è·µã€‚\\né“¾ï¼šé“¾è¶…è¶Šäº†å•ä¸€ LLM è°ƒç”¨ï¼Œæ˜¯è°ƒç”¨çš„åºåˆ—ï¼ˆæ— è®ºæ˜¯å¯¹ LLM è¿˜æ˜¯å…¶ä»–å·¥å…·ï¼‰ã€‚LangChain æä¾›äº†é“¾çš„æ ‡å‡†æ¥å£ã€ä¸å…¶ä»–å·¥å…·çš„ä¼—å¤šé›†æˆï¼Œä»¥åŠç”¨äºå¸¸è§åº”ç”¨ç¨‹åºçš„ç«¯åˆ°ç«¯é“¾ã€‚\\nä»£ç†ï¼šä»£ç†æ¶‰åŠ LLM æ ¹æ®è¦é‡‡å–çš„æ“ä½œåšå‡ºå†³ç­–ï¼Œé‡‡å–è¯¥æ“ä½œï¼ŒæŸ¥çœ‹è§‚å¯Ÿç»“æœï¼Œå¹¶é‡å¤è¯¥è¿‡ç¨‹ï¼Œç›´åˆ°å®Œæˆã€‚LangChain æä¾›äº†ä»£ç†çš„æ ‡å‡†æ¥å£ã€å¯ä¾›é€‰æ‹©çš„ä»£ç†é›†åˆä»¥åŠç«¯åˆ°ç«¯ä»£ç†çš„ç¤ºä¾‹ã€‚\\n\\n\\n\\n\\n\\nç”¨ä¾‹#\\nä¸Šè¿°æ¨¡å—å¯ä»¥ä»¥å¤šç§æ–¹å¼ä½¿ç”¨ã€‚LangChain è¿˜æä¾›äº†æŒ‡å¯¼å’Œå¸®åŠ©ã€‚ä»¥ä¸‹æ˜¯ LangChain æ”¯æŒçš„ä¸€äº›å¸¸è§ç”¨ä¾‹ã€‚\\n\\nä¸ªäººåŠ©ç†ï¼šä¸»è¦çš„ LangChain ç”¨ä¾‹ã€‚ä¸ªäººåŠ©ç†éœ€è¦é‡‡å–è¡ŒåŠ¨ã€è®°ä½äº¤äº’å¹¶äº†è§£æ‚¨çš„æ•°æ®ã€‚\\né—®ç­”ï¼šç¬¬äºŒä¸ªé‡è¦çš„ LangChain ç”¨ä¾‹ã€‚ä»…åˆ©ç”¨è¿™äº›æ–‡æ¡£ä¸­çš„ä¿¡æ¯æ¥å›ç­”ç‰¹å®šæ–‡æ¡£ä¸Šçš„é—®é¢˜ã€‚\\nèŠå¤©æœºå™¨äººï¼šç”±äºè¯­è¨€æ¨¡å‹æ“…é•¿ç”Ÿæˆæ–‡æœ¬ï¼Œè¿™ä½¿å¾—å®ƒä»¬éå¸¸é€‚åˆåˆ›å»ºèŠå¤©æœºå™¨äººã€‚\\næŸ¥è¯¢è¡¨æ ¼æ•°æ®ï¼šå¦‚æœæ‚¨æƒ³äº†è§£å¦‚ä½•ä½¿ç”¨ LLMs æŸ¥è¯¢å­˜å‚¨åœ¨è¡¨æ ¼æ ¼å¼ï¼ˆcsvã€SQLã€æ•°æ®æ¡†ç­‰ï¼‰ä¸­çš„æ•°æ®ï¼Œæ‚¨åº”è¯¥é˜…è¯»æ­¤é¡µé¢ã€‚\\nä¸ API äº¤äº’ï¼šä½¿ LLMs ä¸ API äº¤äº’æ˜¯éå¸¸å¼ºå¤§çš„ï¼Œå¯ä»¥ä¸ºå®ƒä»¬æä¾›æ›´å®æ—¶çš„ä¿¡æ¯å¹¶å…è®¸å®ƒä»¬é‡‡å–è¡ŒåŠ¨ã€‚\\næå–ï¼šä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚\\næ‘˜è¦ï¼šå°†è¾ƒé•¿çš„æ–‡æ¡£æ€»ç»“ä¸ºæ›´çŸ­ã€æ›´ç²¾ç‚¼çš„ä¿¡æ¯å—ã€‚è¿™ä¹Ÿæ˜¯ä¸€ç§æ•°æ®å¢å¼ºç”Ÿæˆã€‚\\nè¯„ä¼°ï¼šç”Ÿæˆæ¨¡å‹é€šå¸¸éš¾ä»¥ä½¿ç”¨ä¼ ç»ŸæŒ‡æ ‡è¿›è¡Œè¯„ä¼°ã€‚è¯„ä¼°å®ƒä»¬çš„ä¸€ç§æ–°æ–¹æ³•æ˜¯ä½¿ç”¨è¯­è¨€æ¨¡å‹æœ¬èº«è¿›è¡Œè¯„ä¼°ã€‚LangChain æä¾›äº†ä¸€äº›æç¤º/é“¾æ¥ååŠ©æ­¤è¿‡ç¨‹ã€‚\\n\\n\\n\\n\\n\\nå‚è€ƒæ–‡æ¡£#\\nLangChain çš„æ‰€æœ‰å‚è€ƒæ–‡æ¡£ï¼Œé›†ä¸­åœ¨ä¸€ä¸ªåœ°æ–¹ã€‚æœ‰å…³æ‰€æœ‰æ–¹æ³•ã€ç±»ã€å®‰è£…æ–¹æ³•å’Œ LangChain é›†æˆè®¾ç½®çš„å®Œæ•´æ–‡æ¡£ã€‚\\n\\nå‚è€ƒæ–‡æ¡£\\n\\n\\n\\n\\n\\nLangChain ç”Ÿæ€ç³»ç»Ÿ#\\næœ‰å…³å…¶ä»–å…¬å¸/äº§å“å¦‚ä½•ä¸ LangChain ä¸€èµ·ä½¿ç”¨çš„æŒ‡å—\\n\\nLangChain ç”Ÿæ€ç³»ç»Ÿ\\n\\n\\n\\n\\n\\né™„åŠ èµ„æº#\\næˆ‘ä»¬è®¤ä¸ºåœ¨æ‚¨å¼€å‘åº”ç”¨ç¨‹åºæ—¶å¯èƒ½æœ‰ç”¨çš„é™„åŠ èµ„æºé›†åˆï¼\\n\\nLangChainHubï¼šLangChainHub æ˜¯ä¸€ä¸ªåˆ†äº«å’Œæ¢ç´¢å…¶ä»–æç¤ºã€é“¾å’Œä»£ç†çš„åœ°æ–¹ã€‚\\nè¯æ±‡è¡¨ï¼šæ‰€æœ‰ç›¸å…³æœ¯è¯­ã€è®ºæ–‡ã€æ–¹æ³•ç­‰çš„è¯æ±‡è¡¨ã€‚æ— è®ºæ˜¯å¦åœ¨ LangChain ä¸­å®ç°ï¼\\nç”»å»Šï¼šæˆ‘ä»¬æœ€å–œæ¬¢çš„ä½¿ç”¨ LangChain çš„é¡¹ç›®é›†åˆã€‚å¯¹äºå¯»æ‰¾çµæ„Ÿæˆ–æŸ¥çœ‹å…¶ä»–åº”ç”¨ç¨‹åºä¸­çš„å®ç°æ–¹å¼éå¸¸æœ‰ç”¨ã€‚\\néƒ¨ç½²ï¼šæœ‰å…³éƒ¨ç½² LangChain åº”ç”¨ç¨‹åºçš„è¯´æ˜ã€ä»£ç ç‰‡æ®µå’Œæ¨¡æ¿åº“çš„é›†åˆã€‚\\nè¿½è¸ªï¼šä½¿ç”¨ LangChain ä¸­çš„è¿½è¸ªå¯è§†åŒ–é“¾å’Œä»£ç†çš„æ‰§è¡Œè¿‡ç¨‹çš„æŒ‡å—ã€‚\\næ¨¡å‹å®éªŒå®¤ï¼šå®éªŒä¸åŒçš„æç¤ºã€æ¨¡å‹å’Œé“¾æ˜¯å¼€å‘æœ€ä½³åº”ç”¨ç¨‹åºçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚æ¨¡å‹å®éªŒå®¤ä½¿è¿™ä¸€è¿‡ç¨‹å˜å¾—ç®€å•ã€‚\\nDiscordï¼šåŠ å…¥æˆ‘ä»¬çš„ Discordï¼Œè®¨è®ºä¸ LangChain ç›¸å…³çš„æ‰€æœ‰å†…å®¹ï¼\\nç”Ÿäº§æ”¯æŒï¼šå½“æ‚¨å°† LangChain è½¬å…¥ç”Ÿäº§æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›æä¾›æ›´å…¨é¢çš„æ”¯æŒã€‚è¯·å¡«å†™æ­¤è¡¨æ ¼ï¼Œæˆ‘ä»¬å°†å»ºç«‹ä¸€ä¸ªä¸“é—¨çš„æ”¯æŒ Slack é¢‘é“ã€‚\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nä¸‹ä¸€ä¸ª\\nå¿«é€Ÿå…¥é—¨æŒ‡å—\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n å†…å®¹\\n  \\n\\n\\nå…¥é—¨\\næ¨¡å—\\nç”¨ä¾‹\\nå‚è€ƒæ–‡æ¡£\\nLangChain ç”Ÿæ€ç³»ç»Ÿ\\né™„åŠ èµ„æº\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nä½œè€…ï¼šHarrison Chase\\n\\n\\n\\n\\n    \\n      Â© ç‰ˆæƒ 2023, Harrison Chase.\\n      \\n\\n\\n\\n\\n  æœ€åæ›´æ–°äº 2023å¹´3æœˆ27æ—¥ã€‚\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\', lookup_str=\'\', metadata={\'source\': \'https://python.langchain.com/en/latest/\', \'loc\': \'https://python.langchain.com/en/latest/\', \'lastmod\': \'2023-03-27T22:50:49.790324+00:00\', \'changefreq\': \'daily\', \'priority\': \'0.9\'}, lookup_index=0)æ·»åŠ è‡ªå®šä¹‰æŠ“å–è§„åˆ™\u200bSitemapLoader ä½¿ç”¨ beautifulsoup4 è¿›è¡ŒæŠ“å–è¿‡ç¨‹ï¼Œé»˜è®¤æƒ…å†µä¸‹ä¼šæŠ“å–é¡µé¢ä¸Šçš„æ¯ä¸ªå…ƒç´ ã€‚SitemapLoader æ„é€ å‡½æ•°æ¥å—è‡ªå®šä¹‰æŠ“å–å‡½æ•°ã€‚æ­¤åŠŸèƒ½å¯ä»¥å¸®åŠ©æ‚¨æ ¹æ®ç‰¹å®šéœ€æ±‚é‡èº«å®šåˆ¶æŠ“å–è¿‡ç¨‹ï¼›ä¾‹å¦‚ï¼Œæ‚¨å¯èƒ½å¸Œæœ›é¿å…æŠ“å–æ ‡é¢˜æˆ–å¯¼èˆªå…ƒç´ ã€‚ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•å¼€å‘å’Œä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°ä»¥é¿å…å¯¼èˆªå’Œæ ‡é¢˜å…ƒç´ ã€‚å¯¼å…¥ beautifulsoup4 åº“å¹¶å®šä¹‰è‡ªå®šä¹‰å‡½æ•°.pip install beautifulsoup4from bs4 import BeautifulSoupdef remove_nav_and_header_elements(content: BeautifulSoup) -> str:    # åœ¨ BeautifulSoup å¯¹è±¡ä¸­æŸ¥æ‰¾æ‰€æœ‰ 'nav' å’Œ 'header' å…ƒç´     nav_elements = content.find_all("nav")    header_elements = content.find_all("header")    # ä» BeautifulSoup å¯¹è±¡ä¸­åˆ é™¤æ¯ä¸ª 'nav' å’Œ 'header' å…ƒç´     for element in nav_elements + header_elements:        element.decompose()    return str(content.get_text())å°†è‡ªå®šä¹‰å‡½æ•°æ·»åŠ åˆ° SitemapLoader å¯¹è±¡ä¸­.loader = SitemapLoader(    "https://langchain.readthedocs.io/sitemap.xml",    filter_urls=["https://python.langchain.com/en/latest/"],    parsing_function=remove_nav_and_header_elements,)æœ¬åœ°ç½‘ç«™åœ°å›¾\u200bç½‘ç«™åœ°å›¾åŠ è½½å™¨è¿˜å¯ä»¥ç”¨äºåŠ è½½æœ¬åœ°æ–‡ä»¶.sitemap_loader = SitemapLoader(web_path="example_data/sitemap.xml", is_local=True)docs = sitemap_loader.load()    Fetching pages: 100%|####################################################################################################################################| 3/3 [00:00<00:00,  3.91it/s]ä¸Šä¸€ä¸ªRSTä¸‹ä¸€ä¸ªSlackè¿‡æ»¤ç½‘ç«™åœ°å›¾ URLsæ·»åŠ è‡ªå®šä¹‰æŠ“å–è§„åˆ™æœ¬åœ°ç½‘ç«™åœ°å›¾ç¤¾åŒºDiscordTwitterGitHubPythonJS/TSæ›´å¤šä¸»é¡µåšå®¢ç‰ˆæƒ Â© 2023 LangChain, Inc.\n\n\n\n', metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/sitemap', 'loc': 'https://python.langchain.com/docs/integrations/document_loaders/sitemap', 'changefreq': 'weekly', 'priority': '0.5'})
```



## æ·»åŠ è‡ªå®šä¹‰æŠ“å–è§„åˆ™

é»˜è®¤æƒ…å†µä¸‹ï¼Œè§£æå™¨**ç§»é™¤**æ‰€æœ‰é™¤æ–‡æ¡£é¡µé¢ä¸»è¦å†…å®¹å¤–çš„å†…å®¹ï¼Œä¸»è¦å†…å®¹é€šå¸¸æ˜¯`<article>`æ ‡ç­¾ã€‚æ‚¨è¿˜å¯ä»¥é€šè¿‡æä¾›ä¸€ä¸ªåŒ…å« HTML æ ‡ç­¾çš„åˆ—è¡¨æ¥å®šä¹‰ä¸€ä¸ª**åŒ…å«**åˆ—è¡¨ï¼Œåˆ©ç”¨`custom_html_tags`å‚æ•°ã€‚ä¾‹å¦‚ï¼š

```python
loader = DocusaurusLoader(
    "https://python.langchain.com",
    filter_urls=[
        "https://python.langchain.com/docs/integrations/document_loaders/sitemap"
    ],
    # è¿™å°†ä»…åŒ…æ‹¬ä¸è¿™äº›æ ‡ç­¾åŒ¹é…çš„å†…å®¹ï¼Œå¦åˆ™å®ƒä»¬å°†è¢«ç§»é™¤
    custom_html_tags=["#content", ".main"],
)
```

å¦‚æœæ‚¨éœ€è¦å¯¹æ¯ä¸ªé¡µé¢è¿”å›çš„å†…å®¹è¿›è¡Œæ›´ç»†ç²’åº¦çš„æ§åˆ¶ï¼Œæ‚¨è¿˜å¯ä»¥å®šä¹‰ä¸€ä¸ªå®Œå…¨è‡ªå®šä¹‰çš„è§£æå‡½æ•°ã€‚

ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•å¼€å‘å’Œä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°ä»¥é¿å…å¯¼èˆªå’Œå¤´éƒ¨å…ƒç´ ã€‚

```python
from bs4 import BeautifulSoup


def remove_nav_and_header_elements(content: BeautifulSoup) -> str:
    # åœ¨ BeautifulSoup å¯¹è±¡ä¸­æŸ¥æ‰¾æ‰€æœ‰ 'nav' å’Œ 'header' å…ƒç´ 
    nav_elements = content.find_all("nav")
    header_elements = content.find_all("header")

    # ä» BeautifulSoup å¯¹è±¡ä¸­ç§»é™¤æ¯ä¸ª 'nav' å’Œ 'header' å…ƒç´ 
    for element in nav_elements + header_elements:
        element.decompose()

    return str(content.get_text())
```

å°†æ‚¨çš„è‡ªå®šä¹‰å‡½æ•°æ·»åŠ åˆ°`DocusaurusLoader`å¯¹è±¡ä¸­ã€‚

```python
loader = DocusaurusLoader(
    "https://python.langchain.com",
    filter_urls=[
        "https://python.langchain.com/docs/integrations/document_loaders/sitemap"
    ],
    parsing_function=remove_nav_and_header_elements,
)
```

## ç›¸å…³

- æ–‡æ¡£åŠ è½½å™¨ [æ¦‚å¿µæŒ‡å—](/docs/concepts/#document-loaders)
- æ–‡æ¡£åŠ è½½å™¨ [æ“ä½œæŒ‡å—](/docs/how_to/#document-loaders)