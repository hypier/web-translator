{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322825540239da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"docs.sillytavern.app\"\n",
    "docs_url = \"https://docs.sillytavern.app/\"\n",
    "!wget -e robots=off --recursive --mirror --no-clobber --page-requisites --html-extension --convert-links --restrict-file-names=windows --domains {domain} --no-parent {docs_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e260d4011323db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langchain langchain_openai python-dotenv portkey-ai pyyaml html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6447bd7bc5489935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "def portkey_llm(model=\"openai/gpt-4o-mini\", temperature=0.5):\n",
    "    PORTKEY_API_KEY = os.getenv(\"PORTKEY_API_KEY\")\n",
    "    OPEN_ROUTER_API_KEY = os.getenv(\"OPEN_ROUTER_API_KEY\")\n",
    "    OPEN_ROUTER_URL = os.getenv(\"OPEN_ROUTER_URL\")\n",
    "\n",
    "    headers = createHeaders(provider=\"openrouter\", api_key=PORTKEY_API_KEY)\n",
    "    # base_url = \"http://localhost:8787/v1\"\n",
    "    # base_url = OPEN_ROUTER_URL\n",
    "    base_url = PORTKEY_GATEWAY_URL\n",
    "    # print(headers)\n",
    "\n",
    "    chat = ChatOpenAI(model=model,\n",
    "                      api_key=OPEN_ROUTER_API_KEY,\n",
    "                      base_url=base_url,\n",
    "                      default_headers=headers,\n",
    "                      temperature=temperature)\n",
    "    return chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67058c8d5cd235f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T01:39:53.859342Z",
     "start_time": "2024-07-28T01:39:53.443817Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import yaml\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "file_path = './docs.sillytavern.app/index.html'\n",
    "file_path1 = './docs.sillytavern.app/index.html.bak'\n",
    "\n",
    "with open(file_path1, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "\n",
    "\n",
    "# \n",
    "# content = '''\n",
    "# <div>a <b>b</b> c <b>d</b>e</div>\n",
    "# '''\n",
    "\n",
    "# 使用BeautifulSoup解析HTML内容\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# 存储元素信息的数组\n",
    "elements_info = []\n",
    "index = 0\n",
    "\n",
    "# 遍历所有元素并获取信息\n",
    "def get_element_info(element):\n",
    "    global index\n",
    "    # 检查节点是否为Tag对象，并且不在排除的标签列表中\n",
    "    if element.name and element.name not in ['script', 'style', 'noscript', 'head', 'link']:\n",
    "        # 获取子节点中的文本内容\n",
    "        text = element.get_text(strip=True)\n",
    "        if re.search(r'\\w', text):\n",
    "            index += 1\n",
    "            elements_info.append({\n",
    "                'index': index,\n",
    "                'tag': element.name,\n",
    "                'text': text,\n",
    "            })\n",
    "    \n",
    "    # 递归遍历子元素\n",
    "    for child in element.children:\n",
    "        if child.name:  # 确保子节点也是Tag对象\n",
    "            get_element_info(child)\n",
    "\n",
    "# 获取所有元素的信息\n",
    "get_element_info(soup)\n",
    "\n",
    "# # 只提取 index 和 text\n",
    "filtered_texts = [{\"index\": item[\"index\"], \"text\": item[\"text\"]} for item in elements_info]\n",
    "\n",
    "# 转换为 YAML 格式\n",
    "yaml_data = yaml.dump(filtered_texts, allow_unicode=True)\n",
    "\n",
    "print(yaml_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce03925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54975598571f0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "system_template = \"\"\"\n",
    "You will be given a YAML formatted input containing entries with \"id\" and \"{imt_source_field}\" fields. \n",
    "\n",
    "For each entry in the YAML, translate the contents of the \"{imt_source_field}\" field into {to}. Write the translation back into the \"{{imt_source_field}}\" field for that entry.\n",
    "\n",
    "Here is an example of the expected format:\n",
    "\n",
    "<example>\n",
    "Input:\n",
    "  - id: 1\n",
    "    {imt_source_field}: Source\n",
    "Output:\n",
    "  - id: 1\n",
    "    {imt_trans_field}: Translation\n",
    "</example>\n",
    "\n",
    "Please return the translated YAML directly without wrapping <yaml> tag or include any additional information.\n",
    "\"\"\"\n",
    "\n",
    "user_template = \"\"\"\n",
    "Here is the input:\n",
    "\n",
    "<yaml>\n",
    "{{yaml}}\n",
    "</yaml>\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = prompt_template | portkey_llm() | parser\n",
    "response = chain.invoke({\"text\": yaml_data, \"to\": \"chinese\", \"imt_source_field\": \"text\", \"imt_trans_field\": \"translation\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1bc3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "translated_texts = yaml.load(response, Loader=yaml.FullLoader)\n",
    "# 将 source_texts 和 translated_texts 通过index 合并\n",
    "for source_text in elements_info:\n",
    "    for translated_text in translated_texts:\n",
    "        if source_text[\"index\"] == translated_text[\"index\"]:\n",
    "            source_text[\"translated\"] = translated_text[\"translation\"]\n",
    "\n",
    "elements_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853bbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffc1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = '''\n",
    "<html>\n",
    "  <body>\n",
    "    <ul>\n",
    "        <li>Mobile-friendly interface</li>\n",
    "        <li>Multiple backend API connectivity (<a href=\"https://github.com/KoboldAI/KoboldAI-Client\">KoboldAI</a> abc, <a href=\"https://github.com/LostRuins/koboldcpp\">KoboldCpp</a>, <a href=\"https://horde.koboldai.net/\">AI Horde</a>, <a href=\"https://github.com/LostRuins/koboldcpp\">NovelAI</a>, <a href=\"https://github.com/oobabooga/text-generation-webui\">Oobabooga's TextGen WebUI</a>, <a href=\"https://chat.openai.com/\">OpenAI</a>, <a href=\"https://windowai.io\">WindowAI</a>, <a href=\"https://openrouter.ai/\">OpenRouter</a>, <a href=\"https://github.com/theroyallab/tabbyAPI\">TabbyAPI</a>, and many more...). See <a href=\"usage/api-connections/index.html\">API connections</a>.</li>\n",
    "        <li>Visual Novel-like Waifu Mode</li>\n",
    "        <li>Horde Stable Diffusion generation</li>\n",
    "        <li>TTS support (ElevenLabs, Silero, etc.)</li>\n",
    "  </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "# 使用BeautifulSoup解析HTML内容\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "\n",
    "# 获取元素的 CSS 选择器\n",
    "def xpath_to_css(xpath) -> str:\n",
    "    # 去掉前导的斜杠\n",
    "    if xpath.startswith('/'):\n",
    "        xpath = xpath[1:]\n",
    "    \n",
    "    if 'comment()' in xpath:\n",
    "        return None\n",
    "        \n",
    "    selectors = []\n",
    "    for part in xpath.split('/'):\n",
    "        if '[' in part:\n",
    "            # 提取标签名和索引\n",
    "            tag, index = re.match(r'([a-zA-Z0-9_-]+)\\[(\\d+)\\]', part).groups()\n",
    "            selectors.append(f'{tag}:nth-of-type({index})')\n",
    "        else:\n",
    "            selectors.append(part)\n",
    "    return ' > '.join(selectors)\n",
    "\n",
    "\n",
    "for element_info in elements_info:\n",
    "\n",
    "    if element_info[\"text\"] == \"Powered by\":\n",
    "        continue\n",
    "\n",
    "    xpath = element_info[\"xpath\"]\n",
    "    translated_text = element_info[\"translated\"]\n",
    "\n",
    "    # 将XPath转换为BeautifulSoup选择器\n",
    "    selectors = xpath_to_css(xpath)\n",
    "    if not selectors:\n",
    "        continue\n",
    "\n",
    "    # 查找并更新元素的文本内容\n",
    "    element = soup.select_one(selectors.strip())\n",
    "    if element:\n",
    "        element.string = translated_text\n",
    "\n",
    "# 将修改后的HTML内容写回文件\n",
    "# with open(file_path, 'w', encoding='utf-8') as file:\n",
    "#     file.write(str(soup))\n",
    "\n",
    "print(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7782d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './docs.sillytavern.app/index.html'\n",
    "file_path1 = './docs.sillytavern.app/index.html.bak'\n",
    "\n",
    "with open(file_path1, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# content = '''\n",
    "# <html>\n",
    "#   <body>\n",
    "#     <div class=\"content\">\n",
    "#       <p id=\"para2\">This is another paragraph.</p>\n",
    "#     </div>\n",
    "#     <div id=\"para3\">abc<b>123</b></div>\n",
    "#     <span>Some text here</span>\n",
    "#     <!-- This is a comment and should be skipped -->\n",
    "#   </body>\n",
    "# </html>\n",
    "# '''\n",
    "\n",
    "# 使用BeautifulSoup解析HTML内容\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb74f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T08:39:28.890982Z",
     "start_time": "2024-07-28T08:39:28.875811Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import re\n",
    "\n",
    "content = '''\n",
    "<div>abc<div>123</div>456</div>\n",
    "<div>\n",
    "<div>def<a>111</a>2342</div>\n",
    "</div>\n",
    "<ul>\n",
    "<li>release -<span class=\"docs-emoji\">&#x1F31F;</span> <strong>Recommended for most users.</strong> This is the most stable and recommended branch, updated only when major releases are pushed. It&#x27;s suitable for the majority of users.</li>\n",
    "<li>staging - <span class=\"docs-emoji\">&#x26A0;&#xFE0F;</span> <strong>Not recommended for casual use.</strong> This branch has the latest features, but be cautious as it may break at any time. Only for power users and enthusiasts.</li>\n",
    "</ul>\n",
    "'''\n",
    "\n",
    "# 使用 html5lib 解析 HTML 文档\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "elements_info = []\n",
    "\n",
    "def get_text_by_tag(tag):\n",
    "    if isinstance(tag, NavigableString):\n",
    "        if re.search(r'\\w', tag):\n",
    "            elements_info.append(str(tag))\n",
    "        return\n",
    "\n",
    "    if all(isinstance(child, NavigableString) for child in tag.contents):\n",
    "        elements_info.append(tag.get_text())\n",
    "        return\n",
    "\n",
    "    for child in tag.children:\n",
    "        get_text_by_tag(child)\n",
    "\n",
    "# 获取文档中所有顶级标签的文本\n",
    "for tag in soup.find_all(recursive=False):\n",
    "    get_text_by_tag(tag)\n",
    "\n",
    "# 打印结果\n",
    "print('\\n@'.join(elements_info))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import re\n",
    "\n",
    "content = '''\n",
    "<div>abc<div>123</div>456</div>\n",
    "<div>\n",
    "<div>def<a>111</a>2342</div>\n",
    "</div>\n",
    "<ul>\n",
    "<li>release -<span class=\"docs-emoji\">&#x1F31F;</span> <strong>Recommended for most users.</strong> This is the most stable and recommended branch, updated only when major releases are pushed. It&#x27;s suitable for the majority of users.</li>\n",
    "<li>staging - <span class=\"docs-emoji\">&#x26A0;&#xFE0F;</span> <strong>Not recommended for casual use.</strong> This branch has the latest features, but be cautious as it may break at any time. Only for power users and enthusiasts.</li>\n",
    "</ul>\n",
    "'''\n",
    "\n",
    "# 使用 html5lib 解析 HTML 文档\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "elements_info = []\n",
    "\n",
    "def get_text_by_tag(tag):\n",
    "    if isinstance(tag, NavigableString):\n",
    "        if re.search(r'\\w', tag):\n",
    "            elements_info.append(str(tag))\n",
    "        return\n",
    "\n",
    "    if all(isinstance(child, NavigableString) for child in tag.contents):\n",
    "        elements_info.append(tag.get_text())\n",
    "        return\n",
    "\n",
    "    for child in tag.children:\n",
    "        get_text_by_tag(child)\n",
    "\n",
    "# 获取文档中所有顶级标签的文本\n",
    "for tag in soup.find_all(recursive=False):\n",
    "    get_text_by_tag(tag)\n",
    "\n",
    "# 打印结果\n",
    "print('\\n@'.join(elements_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a02a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T09:19:55.539038Z",
     "start_time": "2024-07-28T09:19:55.232685Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import re\n",
    "\n",
    "file_path = './docs.sillytavern.app/index.html'\n",
    "file_path1 = './docs.sillytavern.app/index.html.bak'\n",
    "\n",
    "with open(file_path1, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "\n",
    "\n",
    "# 使用 html5lib 解析 HTML 文档\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "elements_info = []\n",
    "\n",
    "def get_text_without_parent_tag(tag):\n",
    "    texts = []\n",
    "    for child in tag.children:\n",
    "        texts.append(str(child))\n",
    "        \n",
    "    text = ''.join(texts)\n",
    "    \n",
    "    return {\n",
    "        'tag': tag.name,\n",
    "        'text': text\n",
    "    }\n",
    "\n",
    "def get_text_by_tag(tag):\n",
    "\n",
    "    if isinstance(tag, NavigableString):\n",
    "        if re.search(r'\\w', tag):\n",
    "            elements_info.append(str(tag).strip())\n",
    "        \n",
    "        return\n",
    "\n",
    "    # 单文本节点, 有文本没有子节点\n",
    "    if len(tag.contents)>0 and is_string(tag.contents):\n",
    "        elements_info.append(get_text_without_parent_tag(tag))\n",
    "        return\n",
    "        \n",
    "    # 如果是包裹元素的文本节点，没有特定标签，直接返回文本内容\n",
    "    if is_string_tag(tag.contents):\n",
    "        elements_info.append(get_text_without_parent_tag(tag))\n",
    "        return\n",
    "\n",
    "    # 如果是包裹元素的文本节点，有特定标签，直接返回文本内容\n",
    "    # todo\n",
    "\n",
    "    # 如果有子节点，递归遍历子节点\n",
    "    for child in tag.children:\n",
    "        get_text_by_tag(child)\n",
    "        \n",
    "def is_string(contents):\n",
    "    return isinstance(contents[0], NavigableString) and not any(isinstance(tag, Tag) for tag in contents)\n",
    "\n",
    "\n",
    "def is_string_tag(contents):\n",
    "    is_navigable_string = False\n",
    "    is_tag = False\n",
    "    \n",
    "    for tag in contents:\n",
    "        if isinstance(tag, NavigableString) and re.search(r'\\w', tag):\n",
    "            is_navigable_string = True\n",
    "        \n",
    "        if isinstance(tag, Tag) and tag.name not in ['div', 'ul']:\n",
    "            is_tag = True\n",
    "    \n",
    "    return is_navigable_string and is_tag\n",
    "\n",
    "\n",
    "all_texts = []\n",
    "\n",
    "for tag in soup.find_all():\n",
    "    get_text_by_tag(tag)\n",
    "\n",
    "for element_info in elements_info:\n",
    "    print(element_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a149816b145773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T00:56:14.598333Z",
     "start_time": "2024-07-29T00:52:51.591342Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def extract_html_info(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    elements_info = []\n",
    "\n",
    "    for element in soup.find_all(True):  # True finds all tags\n",
    "        tag = element.name\n",
    "        text = ''.join([str(c) for c in element.contents if isinstance(c, str)]).strip()\n",
    "        \n",
    "        if tag in ['script', 'style', 'noscript', 'head', 'link']:\n",
    "            continue\n",
    "\n",
    "        # Skip elements with empty text\n",
    "        if not text or not re.search(r'\\w', text):\n",
    "            continue\n",
    "\n",
    "        # Generate CSS selector\n",
    "        path = []\n",
    "        current = element\n",
    "        while current:\n",
    "            sibling_count = 0\n",
    "            if current.parent:\n",
    "                for sibling in current.parent.find_all(current.name, recursive=False):\n",
    "                    if sibling is current:\n",
    "                        break\n",
    "                    sibling_count += 1\n",
    "                path.append(f\"{current.name}:nth-of-type({sibling_count + 1})\")\n",
    "                current = current.parent\n",
    "            else:\n",
    "                path.append(current.name)\n",
    "                break\n",
    "\n",
    "        css_selector = \" > \".join(reversed(path))\n",
    "\n",
    "        elements_info.append({\n",
    "            'tag': tag,\n",
    "            'text': text,\n",
    "            # 'css_selector': css_selector\n",
    "        })\n",
    "\n",
    "    return elements_info\n",
    "\n",
    "\n",
    "# file_path = './docs.sillytavern.app/index.html'\n",
    "# file_path1 = './docs.sillytavern.app/index.html.bak'\n",
    "# \n",
    "# with open(file_path1, 'r', encoding='utf-8') as file:\n",
    "#     content = file.read()\n",
    "\n",
    "content = \"\"\"\n",
    "<li>Multiple backend API connectivity (\n",
    "<a href=\"https://github.com/KoboldAI/KoboldAI-Client\">KoboldAI</a>, \n",
    "<a href=\"https://github.com/LostRuins/koboldcpp\">KoboldCpp</a>, <a href=\"https://horde.koboldai.net/\">AI Horde</a>, <a href=\"https://github.com/LostRuins/koboldcpp\">NovelAI</a>, <a href=\"https://github.com/oobabooga/text-generation-webui\">Oobabooga's TextGen WebUI</a>, <a href=\"https://chat.openai.com/\">OpenAI</a>, <a href=\"https://windowai.io\">WindowAI</a>, <a href=\"https://openrouter.ai/\">OpenRouter</a>, <a href=\"https://github.com/theroyallab/tabbyAPI\">TabbyAPI</a>, and many more...). See <a href=\"usage/api-connections/index.html\">API connections</a>.</li>\n",
    "<li>Visual Novel-like Waifu Mode</li>\n",
    "\"\"\"\n",
    "    \n",
    "elements_info = extract_html_info(content)\n",
    "for info in elements_info:\n",
    "    print(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f1bcebd79ebc793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "markup = '<a href=\"http://example.com/\">I linked to <i>example.com</i></a>'\n",
    "soup = BeautifulSoup(markup)\n",
    "\n",
    "tag = soup.a\n",
    "tag.string = \"111\"\n",
    "type(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_text_by_tag(self, tag):\n",
    "\n",
    "        if isinstance(tag, NavigableString):\n",
    "            self.tag_list.append(tag)\n",
    "            return\n",
    "\n",
    "        if tag.string and re.search(r'\\w', tag.string) and tag.contents and not any(isinstance(t, Tag) for t in tag.contents):  # If it's a NavigableString and not a Tag\n",
    "            self.tag_list.append(tag.string)\n",
    "            return\n",
    "\n",
    "        for child in tag.children:\n",
    "            if isinstance(child, NavigableString):\n",
    "                 self.tag_list.append(child)\n",
    "                 return\n",
    "            elif isinstance(child, Tag):\n",
    "                self.tag_list.extend(self.get_text_by_tag(child))\n",
    "                return\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
